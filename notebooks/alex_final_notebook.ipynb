{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slice and Dice project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "The dataset I am using comes from a study which set out to characterize the gene expression associated with head and neck squamous cell carcinoma (HNSCC) [1]. \n",
    "\n",
    "This dataset consists of a gene expression matrix of 23,686 genes/ORFs x 5902 single cells. The cells came were derived from tumors of HNSCC 18 patients, including five matched pairs of primary tumors and lymph node metastases. Control cells derived from non-tumor tissues were also sequenced.\n",
    "\n",
    "The data came in the form of a 90mb gzipped tab-delimited ```.txt.gz``` file downloaded from the Gene Expression Omnibus [2].\n",
    "I attempted to use ```gunzip``` (equivalent to ```gzip -d```) on this file. It ultimately produced an error message but it also wrote an unzipped ```.txt``` file of size ~400 MB. This file may be truncated and not the full length.\n",
    "\n",
    "Here is the error message:\n",
    "```\n",
    "gzip: GSE103322_HNSCC_all_data.txt.gz: Device or resource busy\n",
    "```\n",
    "\n",
    "Nevertheless, using commands like ```gzip.open()``` or the built in decompression in ```numpy``` or ```pandas``` does not seem to produce any error messages, so I opted to leave the file zipped and use these kinds of methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Dataset\n",
    "\n",
    "\n",
    "\n",
    "I decided to create a smaller test file using only the first ten rows of my dataset. I did this using a simple bash script.\n",
    "\n",
    "```\n",
    " gzip -cd GSE103322_HNSCC_all_data.txt.gz | head > test.txt\n",
    "```\n",
    "\n",
    "I subsequently used ```gzip test.txt``` to create a gzipped file called ```test.txt.gz```.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "The datafile contained 6 rows of metadata and one column of gene names (metadata also). This was included in the gzipped file. I did this to practice working with such a datafile in python and to retain some of the important metadata, like sample names, gene names, and cancer vs non-cancer cell.\n",
    "\n",
    "I worked with this test dataset to help figure out a ton of the code I use below.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import gzip\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymc3 as pm\n",
    "import theano.tensor as tt\n",
    "import toyplot\n",
    "from statsmodels.stats.moment_helpers import corr2cov, cov2corr\n",
    "import h5py\n",
    "#import dask.array as da #maybe not necessary?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attempting to use H5PY...\n",
    "\n",
    "I attempted to use H5PY to facilitate working with a very large gene expression matrix dataset, but things did not go as planned. I think this was just a bit above my comfort level with Python and I wasn't able to figure things out before the deadline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Can't broadcast (6, 5903) -> (3999, 5903)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-2fb0b60c8329>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;31m# stick into db\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[0mdb\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mchunk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mchunk\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mchunks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[0mbigdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\h5py\\_hl\\dataset.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, args, val)\u001b[0m\n\u001b[0;32m    629\u001b[0m             \u001b[0mmshape_pad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    630\u001b[0m         \u001b[0mmspace\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5s\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_simple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmshape_pad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mh5s\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUNLIMITED\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmshape_pad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 631\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mfspace\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mselection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbroadcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    632\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmspace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfspace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdxpl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dxpl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\h5py\\_hl\\selections.py\u001b[0m in \u001b[0;36mbroadcast\u001b[1;34m(self, target_shape)\u001b[0m\n\u001b[0;32m    297\u001b[0m                     \u001b[0mtshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 299\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Can't broadcast %s -> %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtarget_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    300\u001b[0m         \u001b[0mtshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreverse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m         \u001b[0mtshape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Can't broadcast (6, 5903) -> (3999, 5903)"
     ]
    }
   ],
   "source": [
    "# opening a file handle\n",
    "with h5py.File(\"db.h5\", 'w') as io5:\n",
    "    \n",
    "    # initializing an empty h5 database\n",
    "    nrows = 24006\n",
    "    ncols = 5903\n",
    "    \n",
    "    db = io5.create_dataset(name='scCounts', shape=(nrows, ncols), dtype=np.float64, compression='gzip')\n",
    "\n",
    "    # iterate over chunks of the input data and fill in the db\n",
    "    ## grab ~4K lines of data\n",
    "    x = 6\n",
    "    chunks = 3999\n",
    "    \n",
    "    bigdata = gzip.open(\"C:\\\\Users\\\\Alexander\\\\PDSB\\\\project\\\\GSE103322_HNSCC_all_data.txt.gz\", 'r')\n",
    "    for chunk in range(x, nrows, chunks):\n",
    "\n",
    "        # fill the array\n",
    "        listdata = []\n",
    "        for line in range(chunk):\n",
    "            listdata.append(bigdata.readline().decode().split(\"\\t\"))\n",
    "        \n",
    "        # convert list of 20K lines to array of floats\n",
    "        data = np.array(listdata)#.astype(np.float64)\n",
    "        \n",
    "        # stick into db\n",
    "        db[chunk:chunk+chunks, :] = data\n",
    "        \n",
    "    bigdata.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not entirely sure. Maybe the problem is that I need to be thinking of exact number of data lines, cols etc?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "4005\n",
      "8004\n",
      "12003\n",
      "16002\n",
      "20001\n",
      "24000\n"
     ]
    }
   ],
   "source": [
    "x = 6\n",
    "chunks = 3999\n",
    "nrows = 24006\n",
    "\n",
    "\n",
    "for chunk in range(x, nrows, chunks):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Too bad. Maybe later; I plan on develping this over the summer! Moving on..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving indices of interesting gene names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I decided to switch from an \"unsupervised\" to a \"supervised\" approach as I was unable to figure out how to optimize pymc3 application on a 20,000+ gene dataset. Simulations showed that the number of rows (genes) mattered more than columns (samples/single cells)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#save first column as a pandas series (squeeze = T)\n",
    "names = pd.read_csv('C:\\\\Users\\\\Alexander\\\\PDSB\\\\project\\\\GSE103322_HNSCC_all_data.txt.gz',\n",
    "                    sep=\"\\t\", usecols = [0], squeeze=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        processed by Maxima enzyme\n",
       "1                        Lymph node\n",
       "2        classified  as cancer cell\n",
       "3    classified as non-cancer cells\n",
       "4              non-cancer cell type\n",
       "5                        'C9orf152'\n",
       "6                           'RPS11'\n",
       "7                           'ELMO2'\n",
       "8                         'CREB3L1'\n",
       "9                           'PNMA1'\n",
       "Name: Unnamed: 0, dtype: object"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "glis = ['SPARC', 'KLF4', 'MALAT1', #EMT, my data\n",
    "        'CCR7', 'CXCR2',  #HNSCC specific biomarkers, apparently\n",
    "        'MMP9',  #metastasis\n",
    "        'VEGFA', #angiogenesis\n",
    "        'KRAS', 'MYC',  #proliferation\n",
    "        'MIF'] #immune penetration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SPARC',\n",
       " 'KLF4',\n",
       " 'MALAT1',\n",
       " 'CCR7',\n",
       " 'CXCR2',\n",
       " 'MMP9',\n",
       " 'VEGFA',\n",
       " 'KRAS',\n",
       " 'MYC',\n",
       " 'MIF']"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\\\bSPARC\\\\b',\n",
       " '\\\\bKLF4\\\\b',\n",
       " '\\\\bMALAT1\\\\b',\n",
       " '\\\\bCCR7\\\\b',\n",
       " '\\\\bCXCR2\\\\b',\n",
       " '\\\\bMMP9\\\\b',\n",
       " '\\\\bVEGFA\\\\b',\n",
       " '\\\\bKRAS\\\\b',\n",
       " '\\\\bMYC\\\\b',\n",
       " '\\\\bMIF\\\\b']"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#regex magic\n",
    "searchforthese = ['\\\\b{0}'.format(i) for i in glis]\n",
    "searchforthese = ['{0}\\\\b'.format(i) for i in searchforthese]\n",
    "searchforthese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\bSPARC\\b\n",
      "20541    'SPARC'\n",
      "Name: Unnamed: 0, dtype: object\n",
      "\n",
      "\n",
      "\\bKLF4\\b\n",
      "362    'KLF4'\n",
      "Name: Unnamed: 0, dtype: object\n",
      "\n",
      "\n",
      "\\bMALAT1\\b\n",
      "8618    'MALAT1'\n",
      "Name: Unnamed: 0, dtype: object\n",
      "\n",
      "\n",
      "\\bCCR7\\b\n",
      "9525    'CCR7'\n",
      "Name: Unnamed: 0, dtype: object\n",
      "\n",
      "\n",
      "\\bCXCR2\\b\n",
      "1749    'CXCR2'\n",
      "Name: Unnamed: 0, dtype: object\n",
      "\n",
      "\n",
      "\\bMMP9\\b\n",
      "11796    'MMP9'\n",
      "Name: Unnamed: 0, dtype: object\n",
      "\n",
      "\n",
      "\\bVEGFA\\b\n",
      "18375    'VEGFA'\n",
      "Name: Unnamed: 0, dtype: object\n",
      "\n",
      "\n",
      "\\bKRAS\\b\n",
      "16513    'KRAS'\n",
      "Name: Unnamed: 0, dtype: object\n",
      "\n",
      "\n",
      "\\bMYC\\b\n",
      "6530    'MYC'\n",
      "Name: Unnamed: 0, dtype: object\n",
      "\n",
      "\n",
      "\\bMIF\\b\n",
      "17503    'MIF'\n",
      "Name: Unnamed: 0, dtype: object\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "searchindex = []\n",
    "for i in searchforthese:\n",
    "    print(i)\n",
    "    print(names[names.str.contains(i) == 1])\n",
    "    print('\\n')\n",
    "    searchindex.append(names[names.str.contains(i) ==1].index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20541     'SPARC'\n",
       "362        'KLF4'\n",
       "8618     'MALAT1'\n",
       "9525       'CCR7'\n",
       "1749      'CXCR2'\n",
       "11796      'MMP9'\n",
       "18375     'VEGFA'\n",
       "16513      'KRAS'\n",
       "6530        'MYC'\n",
       "17503       'MIF'\n",
       "Name: Unnamed: 0, dtype: object"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names[searchindex]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These genes are all really interesting. They are all implicated in cancer in various ways. Some of these are specifically implicated in the Epithelial-Mesenchymal Transition (EMT). EMT is a key morphological and molecular event in which cancer cells lose epithelial characteristics and gain stem-cell like ones, including motility and increased proliferation. It is linked to disease progression via metastasis, along with poor prognosis. Furthermore, it is known to have a distinct gene expression profile, which I spent some time last semester characterizing.\n",
    "\n",
    "SPARC is a gene involved in the EMT program. I used this gene as a \"seed\" for an unsupervised machine learning software implemented in R for a project last semester developed by the group of Dr. Dimitris Anastassiou. I identified a number of genes with a high degree of mutual information (MI) association with SPARC using this software on a pancreatic cancer mouse model single-cell RNA-seq dataset. The resulting detected genes included KLF4 and MALAT1.\n",
    "\n",
    "KLF4 is a fascinating gene, the role of which in EMT is controversial. Basically, it is thought to support the process of EMT in some contexts but suppress it in others. HNSCC is one cancer type where evidence exists for pro-EMT activity [3]. There is contradictory evidence for its role in pancreatic cancer, the type of dataset I detected this gene in. Additionally, KLF4 is one of the famous \"Yamanaka Factors\" used to artifically cause cellular de-differentiation in order to produce induced pluripotent stem cells (iPSCs).\n",
    "\n",
    "MALAT1 is another interesting EMT-related gene I detected. As the name implies, it is thought to be involved in metastasis (\"metastasis associated lung adenocarcinoma transcript 1\"). This is actually a long-noncoding RNA which is thought to regulate a number of important oncogenic and onco-supportive genes, including genes associated with EMT and metastasis. It is also involved in a number of other non-cancerous pathologies.\n",
    "\n",
    "CCR7 and CXCR2 are two genes that have been implicated specifically in HNSCC; expression of these genes has been proposed as a biomarker for disease in this type of cancer [4].\n",
    "\n",
    "I selected the rest of the genes because they are well-known players in disease progression. MMP9 is involved in metastasis. VEGFA is a central player in angiogenesis. KRAS and MYC are implicated in uncontrolled cell proliferation. Finally, MIF is a marker of immune invasion into tumors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying to use Pymc3\n",
    "\n",
    "I decided to try out pymc3 using the model that I worked out with Professor Eaton to apply on the simulated data. I used this on a skeleton dataset, randomly selecting each thirteen column of the gene expression matrix, ultimately resulting in a much more manageable 10 x 454 data matrix.\n",
    "\n",
    "I did this because the simulation worked well on a matrix of size 10 x 500. However, I should have realized the bad omen when I noticed that 13 is a perfect divisor of 5902, the number of cells in my dataset.\n",
    "\n",
    "Pymc3 returns a memory error of some type, despite working on a similar simulated dataset. I believe that I will have to tweak the model priors to optimize it for this true biological data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = range(1,5903,13)\n",
    "gem = np.loadtxt('C:\\\\Users\\\\Alexander\\\\PDSB\\\\project\\\\GSE103322_HNSCC_all_data.txt.gz', skiprows=6, usecols = cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = gem[searchindex,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 454)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "xsize = x.shape[1]\n",
    "xmeans = x.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as model:\n",
    "    \n",
    "    # distribution to draw stds from (not a rv for now) but is a wide prior\n",
    "    stds = pm.HalfCauchy.dist(2)\n",
    "    \n",
    "    # sample correlations by drawing halfCauchy std values\n",
    "    # eta=1 is uniform corrs, eta>1 puts more weight on corr=0.\n",
    "    packed = pm.LKJCholeskyCov('packed_chol', n=xsize, eta=1., sd_dist=stds)\n",
    "    \n",
    "    # expand correlation matrix and define VCV as dot product\n",
    "    chol = pm.expand_packed_triangular(xsize, packed)\n",
    "    cov = pm.Deterministic('cov', chol.dot(chol.T))\n",
    "    sigma = pm.Deterministic('sigma', tt.sqrt(tt.diag(cov)))\n",
    "\n",
    "    # draw the means from a normal with starting values from observed means\n",
    "    # set this mean and std of this dist according to your data, or it could\n",
    "    # be made into a random variable to be fit.\n",
    "    means = pm.Normal('means', 5, 5, shape=xsize, testval=xmeans)\n",
    "    obs = pm.MvNormal('obs', means, chol=chol, observed=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (3 chains in 3 jobs)\n",
      "NUTS: [means, packed_chol_cholesky_cov_packed__]\n"
     ]
    },
    {
     "ename": "JoblibMemoryError",
     "evalue": "JoblibMemoryError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\nC:\\Users\\Alexander\\Miniconda3\\lib\\runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\nC:\\Users\\Alexander\\Miniconda3\\lib\\runpy.py in _run_code(code=<code object <module> at 0x000000F6A7387030, fil...lib\\site-packages\\ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\Users\\Alexander\\Miniconda3\\lib\\site-packages\\__pycache__\\ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\Users\\Alexander\\Miniconda3\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\Users\\\\A...a3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x000000F6A7387030, fil...lib\\site-packages\\ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\Users\\Alexander\\Miniconda3\\lib\\site-packages\\__pycache__\\ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\Users\\Alexander\\Miniconda3\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\Users\\\\A...a3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\nC:\\Users\\Alexander\\Miniconda3\\lib\\site-packages\\ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\nC:\\Users\\Alexander\\Miniconda3\\lib\\site-packages\\traitlets\\config\\application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\nC:\\Users\\Alexander\\Miniconda3\\lib\\site-packages\\ipykernel\\kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    481         if self.poller is not None:\n    482             self.poller.start()\n    483         self.kernel.start()\n    484         self.io_loop = ioloop.IOLoop.current()\n    485         try:\n--> 486             self.io_loop.start()\n        self.io_loop.start = <bound method BaseAsyncIOLoop.start of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n    487         except KeyboardInterrupt:\n    488             pass\n    489 \n    490 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\nC:\\Users\\Alexander\\Miniconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py in start(self=<tornado.platform.asyncio.AsyncIOMainLoop object>)\n    122         except (RuntimeError, AssertionError):\n    123             old_loop = None\n    124         try:\n    125             self._setup_logging()\n    126             asyncio.set_event_loop(self.asyncio_loop)\n--> 127             self.asyncio_loop.run_forever()\n        self.asyncio_loop.run_forever = <bound method BaseEventLoop.run_forever of <_Win...EventLoop running=True closed=False debug=False>>\n    128         finally:\n    129             asyncio.set_event_loop(old_loop)\n    130 \n    131     def stop(self):\n\n...........................................................................\nC:\\Users\\Alexander\\Miniconda3\\lib\\asyncio\\base_events.py in run_forever(self=<_WindowsSelectorEventLoop running=True closed=False debug=False>)\n    417             sys.set_asyncgen_hooks(firstiter=self._asyncgen_firstiter_hook,\n    418                                    finalizer=self._asyncgen_finalizer_hook)\n    419         try:\n    420             events._set_running_loop(self)\n    421             while True:\n--> 422                 self._run_once()\n        self._run_once = <bound method BaseEventLoop._run_once of <_Windo...EventLoop running=True closed=False debug=False>>\n    423                 if self._stopping:\n    424                     break\n    425         finally:\n    426             self._stopping = False\n\n...........................................................................\nC:\\Users\\Alexander\\Miniconda3\\lib\\asyncio\\base_events.py in _run_once(self=<_WindowsSelectorEventLoop running=True closed=False debug=False>)\n   1427                         logger.warning('Executing %s took %.3f seconds',\n   1428                                        _format_handle(handle), dt)\n   1429                 finally:\n   1430                     self._current_handle = None\n   1431             else:\n-> 1432                 handle._run()\n        handle._run = <bound method Handle._run of <Handle IOLoop._run_callback(functools.par...00F6B46B5268>))>>\n   1433         handle = None  # Needed to break cycles when an exception occurs.\n   1434 \n   1435     def _set_coroutine_wrapper(self, enabled):\n   1436         try:\n\n...........................................................................\nC:\\Users\\Alexander\\Miniconda3\\lib\\asyncio\\events.py in _run(self=<Handle IOLoop._run_callback(functools.par...00F6B46B5268>))>)\n    140             self._callback = None\n    141             self._args = None\n    142 \n    143     def _run(self):\n    144         try:\n--> 145             self._callback(*self._args)\n        self._callback = <bound method IOLoop._run_callback of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n        self._args = (functools.partial(<function wrap.<locals>.null_wrapper at 0x000000F6B46B5268>),)\n    146         except Exception as exc:\n    147             cb = _format_callback_source(self._callback, self._args)\n    148             msg = 'Exception in callback {}'.format(cb)\n    149             context = {\n\n...........................................................................\nC:\\Users\\Alexander\\Miniconda3\\lib\\site-packages\\tornado\\ioloop.py in _run_callback(self=<tornado.platform.asyncio.AsyncIOMainLoop object>, callback=functools.partial(<function wrap.<locals>.null_wrapper at 0x000000F6B46B5268>))\n    754         \"\"\"Runs a callback with error handling.\n    755 \n    756         For use in subclasses.\n    757         \"\"\"\n    758         try:\n--> 759             ret = callback()\n        ret = undefined\n        callback = functools.partial(<function wrap.<locals>.null_wrapper at 0x000000F6B46B5268>)\n    760             if ret is not None:\n    761                 from tornado import gen\n    762                 # Functions that return Futures typically swallow all\n    763                 # exceptions and store them in the Future.  If a Future\n\n...........................................................................\nC:\\Users\\Alexander\\Miniconda3\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=(), **kwargs={})\n    271         # Fast path when there are no active contexts.\n    272         def null_wrapper(*args, **kwargs):\n    273             try:\n    274                 current_state = _state.contexts\n    275                 _state.contexts = cap_contexts[0]\n--> 276                 return fn(*args, **kwargs)\n        args = ()\n        kwargs = {}\n    277             finally:\n    278                 _state.contexts = current_state\n    279         null_wrapper._wrapped = True\n    280         return null_wrapper\n\n...........................................................................\nC:\\Users\\Alexander\\Miniconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in <lambda>()\n    531             return\n    532 \n    533         if state & self.socket.events:\n    534             # events still exist that haven't been processed\n    535             # explicitly schedule handling to avoid missing events due to edge-triggered FDs\n--> 536             self.io_loop.add_callback(lambda : self._handle_events(self.socket, 0))\n    537 \n    538     def _init_io_state(self):\n    539         \"\"\"initialize the ioloop event handler\"\"\"\n    540         with stack_context.NullContext():\n\n...........................................................................\nC:\\Users\\Alexander\\Miniconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=0)\n    445             return\n    446         zmq_events = self.socket.EVENTS\n    447         try:\n    448             # dispatch events:\n    449             if zmq_events & zmq.POLLIN and self.receiving():\n--> 450                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    451                 if not self.socket:\n    452                     return\n    453             if zmq_events & zmq.POLLOUT and self.sending():\n    454                 self._handle_send()\n\n...........................................................................\nC:\\Users\\Alexander\\Miniconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    475             else:\n    476                 raise\n    477         else:\n    478             if self._recv_callback:\n    479                 callback = self._recv_callback\n--> 480                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    481         \n    482 \n    483     def _handle_send(self):\n    484         \"\"\"Handle a send event.\"\"\"\n\n...........................................................................\nC:\\Users\\Alexander\\Miniconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    427         close our socket.\"\"\"\n    428         try:\n    429             # Use a NullContext to ensure that all StackContexts are run\n    430             # inside our blanket exception handler rather than outside.\n    431             with stack_context.NullContext():\n--> 432                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    433         except:\n    434             gen_log.error(\"Uncaught exception in ZMQStream callback\",\n    435                           exc_info=True)\n    436             # Re-raise the exception so that IOLoop.handle_callback_exception\n\n...........................................................................\nC:\\Users\\Alexander\\Miniconda3\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    271         # Fast path when there are no active contexts.\n    272         def null_wrapper(*args, **kwargs):\n    273             try:\n    274                 current_state = _state.contexts\n    275                 _state.contexts = cap_contexts[0]\n--> 276                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    277             finally:\n    278                 _state.contexts = current_state\n    279         null_wrapper._wrapped = True\n    280         return null_wrapper\n\n...........................................................................\nC:\\Users\\Alexander\\Miniconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\nC:\\Users\\Alexander\\Miniconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': 'with model:\\n    trace = pm.sample(tune=1000, draws=5000, njobs=3, cores=3)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 5, 12, 1, 18, 29, 703076, tzinfo=tzutc()), 'msg_id': 'aa95a188ac3d4ec08b465d8804041749', 'msg_type': 'execute_request', 'session': '9c3da7d992cc47ad83ff17e0afaa95be', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'aa95a188ac3d4ec08b465d8804041749', 'msg_type': 'execute_request', 'parent_header': {}})\n    228             self.log.warn(\"Unknown message type: %r\", msg_type)\n    229         else:\n    230             self.log.debug(\"%s: %s\", msg_type, msg)\n    231             self.pre_handler_hook()\n    232             try:\n--> 233                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'9c3da7d992cc47ad83ff17e0afaa95be']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': 'with model:\\n    trace = pm.sample(tune=1000, draws=5000, njobs=3, cores=3)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 5, 12, 1, 18, 29, 703076, tzinfo=tzutc()), 'msg_id': 'aa95a188ac3d4ec08b465d8804041749', 'msg_type': 'execute_request', 'session': '9c3da7d992cc47ad83ff17e0afaa95be', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'aa95a188ac3d4ec08b465d8804041749', 'msg_type': 'execute_request', 'parent_header': {}}\n    234             except Exception:\n    235                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    236             finally:\n    237                 self.post_handler_hook()\n\n...........................................................................\nC:\\Users\\Alexander\\Miniconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'9c3da7d992cc47ad83ff17e0afaa95be'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': 'with model:\\n    trace = pm.sample(tune=1000, draws=5000, njobs=3, cores=3)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 5, 12, 1, 18, 29, 703076, tzinfo=tzutc()), 'msg_id': 'aa95a188ac3d4ec08b465d8804041749', 'msg_type': 'execute_request', 'session': '9c3da7d992cc47ad83ff17e0afaa95be', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'aa95a188ac3d4ec08b465d8804041749', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\nC:\\Users\\Alexander\\Miniconda3\\lib\\site-packages\\ipykernel\\ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='with model:\\n    trace = pm.sample(tune=1000, draws=5000, njobs=3, cores=3)', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    203 \n    204         self._forward_input(allow_stdin)\n    205 \n    206         reply_content = {}\n    207         try:\n--> 208             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = 'with model:\\n    trace = pm.sample(tune=1000, draws=5000, njobs=3, cores=3)'\n        store_history = True\n        silent = False\n    209         finally:\n    210             self._restore_input()\n    211 \n    212         if res.error_before_exec is not None:\n\n...........................................................................\nC:\\Users\\Alexander\\Miniconda3\\lib\\site-packages\\ipykernel\\zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=('with model:\\n    trace = pm.sample(tune=1000, draws=5000, njobs=3, cores=3)',), **kwargs={'silent': False, 'store_history': True})\n    532             )\n    533         self.payload_manager.write_payload(payload)\n    534 \n    535     def run_cell(self, *args, **kwargs):\n    536         self._last_traceback = None\n--> 537         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = ('with model:\\n    trace = pm.sample(tune=1000, draws=5000, njobs=3, cores=3)',)\n        kwargs = {'silent': False, 'store_history': True}\n    538 \n    539     def _showtraceback(self, etype, evalue, stb):\n    540         # try to preserve ordering of tracebacks and print statements\n    541         sys.stdout.flush()\n\n...........................................................................\nC:\\Users\\Alexander\\Miniconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='with model:\\n    trace = pm.sample(tune=1000, draws=5000, njobs=3, cores=3)', store_history=True, silent=False, shell_futures=True)\n   2657         -------\n   2658         result : :class:`ExecutionResult`\n   2659         \"\"\"\n   2660         try:\n   2661             result = self._run_cell(\n-> 2662                 raw_cell, store_history, silent, shell_futures)\n        raw_cell = 'with model:\\n    trace = pm.sample(tune=1000, draws=5000, njobs=3, cores=3)'\n        store_history = True\n        silent = False\n        shell_futures = True\n   2663         finally:\n   2664             self.events.trigger('post_execute')\n   2665             if not silent:\n   2666                 self.events.trigger('post_run_cell', result)\n\n...........................................................................\nC:\\Users\\Alexander\\Miniconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in _run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='with model:\\n    trace = pm.sample(tune=1000, draws=5000, njobs=3, cores=3)', store_history=True, silent=False, shell_futures=True)\n   2780                 self.displayhook.exec_result = result\n   2781 \n   2782                 # Execute the user code\n   2783                 interactivity = 'none' if silent else self.ast_node_interactivity\n   2784                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2785                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2786                 \n   2787                 self.last_execution_succeeded = not has_raised\n   2788                 self.last_execution_result = result\n   2789 \n\n...........................................................................\nC:\\Users\\Alexander\\Miniconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.With object>], cell_name='<ipython-input-189-7f2adb20e97e>', interactivity='none', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at f6b240a7b8, execution...rue silent=False shell_futures=True> result=None>)\n   2898 \n   2899         try:\n   2900             for i, node in enumerate(to_run_exec):\n   2901                 mod = ast.Module([node])\n   2902                 code = compiler(mod, cell_name, \"exec\")\n-> 2903                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x000000F6B026EDB0, file \"<ipython-input-189-7f2adb20e97e>\", line 1>\n        result = <ExecutionResult object at f6b240a7b8, execution...rue silent=False shell_futures=True> result=None>\n   2904                     return True\n   2905 \n   2906             for i, node in enumerate(to_run_interactive):\n   2907                 mod = ast.Interactive([node])\n\n...........................................................................\nC:\\Users\\Alexander\\Miniconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x000000F6B026EDB0, file \"<ipython-input-189-7f2adb20e97e>\", line 1>, result=<ExecutionResult object at f6b240a7b8, execution...rue silent=False shell_futures=True> result=None>)\n   2958         outflag = True  # happens in more places, so it's easier as default\n   2959         try:\n   2960             try:\n   2961                 self.hooks.pre_run_code_hook()\n   2962                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2963                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x000000F6B026EDB0, file \"<ipython-input-189-7f2adb20e97e>\", line 1>\n        self.user_global_ns = {'In': ['', \"import warnings\\nwarnings.simplefilter(action='ig...cov, cov2corr\\nimport h5py\\nimport dask.array as da\", '# opening a file handle\\nwith h5py.File(\"db.h5\", ...nk+chunks, :] = data\\n        \\n    bigdata.close()', '# opening a file handle\\nwith h5py.File(\"db.h5\", ...nk+chunks, :] = data\\n        \\n    bigdata.close()', \"import warnings\\nwarnings.simplefilter(action='ig...cov, cov2corr\\nimport h5py\\nimport dask.array as da\", '# opening a file handle\\nwith h5py.File(\"db.h5\", ...nk+chunks, :] = data\\n        \\n    bigdata.close()', '# opening a file handle\\nwith h5py.File(\"db.h5\", ...nk+chunks, :] = data\\n        \\n    bigdata.close()', '# opening a file handle\\nwith h5py.File(\"db.h5\", ...nk+chunks, :] = data\\n        \\n    bigdata.close()', '# opening a file handle\\nwith h5py.File(\"db.h5\", ...nk+chunks, :] = data\\n        \\n    bigdata.close()', '# opening a file handle\\nwith h5py.File(\"db.h5\", ...nk+chunks, :] = data\\n        \\n    bigdata.close()', 'for chunk in range(x, totrows, chunks)\\n    print(chunk)', 'for chunk in range(x, totrows, chunks):\\n    print(chunk)', '# opening a file handle\\nwith h5py.File(\"db.h5\", ...nk+chunks, :] = data\\n        \\n    bigdata.close()', '# opening a file handle\\nwith h5py.File(\"db.h5\", ...nk+chunks, :] = data\\n        \\n    bigdata.close()', '# opening a file handle\\nwith h5py.File(\"db.h5\", ...nk+chunks, :] = data\\n        \\n    bigdata.close()', 'for chunk in range(x, totrows, chunks):\\n    print(chunk)', 'for chunk in range(x, nrows, chunks):\\n    print(chunk)', 'for chunk in range(x, nrows, chunks):\\n    print(chunk)', '# opening a file handle\\nwith h5py.File(\"db.h5\", ...nk+chunks, :] = data\\n        \\n    bigdata.close()', 'for chunk in range(x, nrows, chunks):\\n    print(chunk)', ...], 'Out': {28: array([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., ....,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]]), 29: array([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]]), 30: array([ 0.]), 31: array([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., ....,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]]), 32: array([[ 0.,  0.,  0.,  0.],\n       [ 0.,  0.,  ...0.,  0.,  0.,  0.],\n       [ 0.,  0.,  0.,  0.]]), 40: (9, 1), 41:   HN28_P15_D06_S330_comb\n0                      ...7                      0\n8                      0, 42:                        Unnamed: 0\n0      process...        'ELMO2'\n8                       'CREB3L1', 44: ['\\tHN28_P15_D06_S330_comb\\tHN28_P6_G05_S173_comb\\tHN...HNSCC20_P3_H08_S92_comb\\tHNSCC20_P3_G06_S78_comb\\r\\n', 'processed by Maxima enzyme\\t1\\t1\\t1\\t1\\t1\\t1\\t1\\t1\\t1\\t1\\t1...0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\r\\n', 'Lymph node\\t1\\t0\\t1\\t1\\t1\\t1\\t1\\t1\\t1\\t1\\t0\\t1\\t1\\t1\\t0\\t0\\t0\\t0\\t1...1\\t0\\t0\\t0\\t0\\t0\\t1\\t0\\t1\\t1\\t0\\t0\\t1\\t0\\t0\\t1\\t0\\t0\\t0\\t0\\t1\\t0\\t0\\t0\\r\\n', 'classified  as cancer cell\\t0\\t0\\t1\\t0\\t1\\t1\\t1\\t0\\t1\\t1\\t0...1\\t1\\t1\\t1\\t1\\t1\\t1\\t0\\t1\\t1\\t1\\t1\\t1\\t1\\t1\\t1\\t1\\t1\\t1\\t0\\t1\\t1\\t1\\t1\\r\\n', 'classified as non-cancer cells\\t1\\t1\\t0\\t1\\t0\\t0\\t0\\t1\\t0...0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\r\\n', 'non-cancer cell type\\tFibroblast\\tFibroblast\\t0\\tFib...0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\r\\n', \"'C9orf152'\\t0\\t0\\t0.42761\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0...0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\r\\n\", \"'RPS11'\\t6.0037\\t7.3006\\t7.2885\\t0\\t7.4742\\t6.9548\\t5.9....5167\\t7.3249\\t5.3595\\t7.4281\\t6.8439\\t6.8676\\t6.3146\\r\\n\", \"'ELMO2'\\t0\\t0\\t0\\t5.2465\\t0.50487\\t0\\t0\\t3.4154\\t0\\t1.9613...0\\t0\\t0\\t0\\t0\\t0\\t0\\t0.62106\\t0\\t0\\t0\\t0\\t0\\t3.2863\\t0\\t3.5905\\r\\n\", \"'CREB3L1'\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0.71...0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\r\\n\"], 53: (23691, 1), ...}, '_': (10, 454), '_100': [True], '_111': [362, 8618, 20263, 11705, 891, 10, 11796, 18375, 9525, 9971, 9971], '_113': [362, 8618, 20263, 11705, 891, 10, 11796, 18375, 9525, 9971, 9971], '_116': [362, 8618, 20263, 11705, 891, 10, 11796, 18375, 9525, 9971, 21328, 1749], '_118': [362, 8618, 20263, 11705, 891, 10, 11796, 18375, 9525, 9971, 21328, 1749], '_119': [362, 8618, 20263, 11705, 891, 10, 11796, 18375, 9525, 9971, 21328, 1749], '_120': [362, 8618, 20263, 11705, 891, 10, 11796, 18375, 9525, 9971, 21328, 1749], ...}\n        self.user_ns = {'In': ['', \"import warnings\\nwarnings.simplefilter(action='ig...cov, cov2corr\\nimport h5py\\nimport dask.array as da\", '# opening a file handle\\nwith h5py.File(\"db.h5\", ...nk+chunks, :] = data\\n        \\n    bigdata.close()', '# opening a file handle\\nwith h5py.File(\"db.h5\", ...nk+chunks, :] = data\\n        \\n    bigdata.close()', \"import warnings\\nwarnings.simplefilter(action='ig...cov, cov2corr\\nimport h5py\\nimport dask.array as da\", '# opening a file handle\\nwith h5py.File(\"db.h5\", ...nk+chunks, :] = data\\n        \\n    bigdata.close()', '# opening a file handle\\nwith h5py.File(\"db.h5\", ...nk+chunks, :] = data\\n        \\n    bigdata.close()', '# opening a file handle\\nwith h5py.File(\"db.h5\", ...nk+chunks, :] = data\\n        \\n    bigdata.close()', '# opening a file handle\\nwith h5py.File(\"db.h5\", ...nk+chunks, :] = data\\n        \\n    bigdata.close()', '# opening a file handle\\nwith h5py.File(\"db.h5\", ...nk+chunks, :] = data\\n        \\n    bigdata.close()', 'for chunk in range(x, totrows, chunks)\\n    print(chunk)', 'for chunk in range(x, totrows, chunks):\\n    print(chunk)', '# opening a file handle\\nwith h5py.File(\"db.h5\", ...nk+chunks, :] = data\\n        \\n    bigdata.close()', '# opening a file handle\\nwith h5py.File(\"db.h5\", ...nk+chunks, :] = data\\n        \\n    bigdata.close()', '# opening a file handle\\nwith h5py.File(\"db.h5\", ...nk+chunks, :] = data\\n        \\n    bigdata.close()', 'for chunk in range(x, totrows, chunks):\\n    print(chunk)', 'for chunk in range(x, nrows, chunks):\\n    print(chunk)', 'for chunk in range(x, nrows, chunks):\\n    print(chunk)', '# opening a file handle\\nwith h5py.File(\"db.h5\", ...nk+chunks, :] = data\\n        \\n    bigdata.close()', 'for chunk in range(x, nrows, chunks):\\n    print(chunk)', ...], 'Out': {28: array([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., ....,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]]), 29: array([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]]), 30: array([ 0.]), 31: array([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., ....,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]]), 32: array([[ 0.,  0.,  0.,  0.],\n       [ 0.,  0.,  ...0.,  0.,  0.,  0.],\n       [ 0.,  0.,  0.,  0.]]), 40: (9, 1), 41:   HN28_P15_D06_S330_comb\n0                      ...7                      0\n8                      0, 42:                        Unnamed: 0\n0      process...        'ELMO2'\n8                       'CREB3L1', 44: ['\\tHN28_P15_D06_S330_comb\\tHN28_P6_G05_S173_comb\\tHN...HNSCC20_P3_H08_S92_comb\\tHNSCC20_P3_G06_S78_comb\\r\\n', 'processed by Maxima enzyme\\t1\\t1\\t1\\t1\\t1\\t1\\t1\\t1\\t1\\t1\\t1...0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\r\\n', 'Lymph node\\t1\\t0\\t1\\t1\\t1\\t1\\t1\\t1\\t1\\t1\\t0\\t1\\t1\\t1\\t0\\t0\\t0\\t0\\t1...1\\t0\\t0\\t0\\t0\\t0\\t1\\t0\\t1\\t1\\t0\\t0\\t1\\t0\\t0\\t1\\t0\\t0\\t0\\t0\\t1\\t0\\t0\\t0\\r\\n', 'classified  as cancer cell\\t0\\t0\\t1\\t0\\t1\\t1\\t1\\t0\\t1\\t1\\t0...1\\t1\\t1\\t1\\t1\\t1\\t1\\t0\\t1\\t1\\t1\\t1\\t1\\t1\\t1\\t1\\t1\\t1\\t1\\t0\\t1\\t1\\t1\\t1\\r\\n', 'classified as non-cancer cells\\t1\\t1\\t0\\t1\\t0\\t0\\t0\\t1\\t0...0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\r\\n', 'non-cancer cell type\\tFibroblast\\tFibroblast\\t0\\tFib...0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\r\\n', \"'C9orf152'\\t0\\t0\\t0.42761\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0...0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\r\\n\", \"'RPS11'\\t6.0037\\t7.3006\\t7.2885\\t0\\t7.4742\\t6.9548\\t5.9....5167\\t7.3249\\t5.3595\\t7.4281\\t6.8439\\t6.8676\\t6.3146\\r\\n\", \"'ELMO2'\\t0\\t0\\t0\\t5.2465\\t0.50487\\t0\\t0\\t3.4154\\t0\\t1.9613...0\\t0\\t0\\t0\\t0\\t0\\t0\\t0.62106\\t0\\t0\\t0\\t0\\t0\\t3.2863\\t0\\t3.5905\\r\\n\", \"'CREB3L1'\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0.71...0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\r\\n\"], 53: (23691, 1), ...}, '_': (10, 454), '_100': [True], '_111': [362, 8618, 20263, 11705, 891, 10, 11796, 18375, 9525, 9971, 9971], '_113': [362, 8618, 20263, 11705, 891, 10, 11796, 18375, 9525, 9971, 9971], '_116': [362, 8618, 20263, 11705, 891, 10, 11796, 18375, 9525, 9971, 21328, 1749], '_118': [362, 8618, 20263, 11705, 891, 10, 11796, 18375, 9525, 9971, 21328, 1749], '_119': [362, 8618, 20263, 11705, 891, 10, 11796, 18375, 9525, 9971, 21328, 1749], '_120': [362, 8618, 20263, 11705, 891, 10, 11796, 18375, 9525, 9971, 21328, 1749], ...}\n   2964             finally:\n   2965                 # Reset our crash handler in place\n   2966                 sys.excepthook = old_excepthook\n   2967         except SystemExit as e:\n\n...........................................................................\nC:\\Users\\Alexander\\PDSB\\project\\<ipython-input-189-7f2adb20e97e> in <module>()\n      1 with model:\n----> 2     trace = pm.sample(tune=1000, draws=5000, njobs=3, cores=3)\n\n...........................................................................\nC:\\Users\\Alexander\\Miniconda3\\lib\\site-packages\\pymc3\\sampling.py in sample(draws=6000, step=<pymc3.step_methods.hmc.nuts.NUTS object>, init='auto', n_init=200000, start=[{'means': array([ -4.62466574e-01,  -1.98349626e-01,   7.2...e+00,   4.53284820e-01,\n         2.34009797e-01]), 'packed_chol_cholesky_cov_packed__': array([-0.68384149, -0.02451297,  0.89029789, ..., -0.95576035,\n        0.00829716,  0.44670675])}, {'means': array([ -6.64825445e-01,  -4.51579275e-01,   2.2...e-01,   4.19604021e-01,\n         9.69156894e-01]), 'packed_chol_cholesky_cov_packed__': array([-0.84918792, -0.75632795, -0.9496933 , ...,  0.91648846,\n       -0.80776874,  0.31534939])}, {'means': array([ -9.26886577e-02,  -7.76855188e-02,  -6.0...e-02,   4.56617830e-01,\n        -7.67655805e-02]), 'packed_chol_cholesky_cov_packed__': array([-0.07061186,  0.33665793,  0.34348559, ..., -0.84164214,\n        0.84913171,  0.71964991])}], trace=None, chain_idx=0, chains=3, cores=3, tune=1000, nuts_kwargs=None, step_kwargs=None, progressbar=True, model=<pymc3.model.Model object>, random_seed=[701098618, 1069148487, 781561441], live_plot=False, discard_tuned_samples=True, live_plot_kwargs=None, compute_convergence_checks=True, use_mmap=False, **kwargs={'njobs': 3})\n    437     parallel = cores > 1 and chains > 1 and not has_population_samplers\n    438     if parallel:\n    439         _log.info('Multiprocess sampling ({} chains in {} jobs)'.format(chains, cores))\n    440         _print_step_hierarchy(step)\n    441         try:\n--> 442             trace = _mp_sample(**sample_args)\n        trace = None\n        sample_args = {'chain': 0, 'chains': 3, 'cores': 3, 'draws': 6000, 'live_plot': False, 'live_plot_kwargs': None, 'model': <pymc3.model.Model object>, 'njobs': 3, 'progressbar': True, 'random_seed': [701098618, 1069148487, 781561441], ...}\n    443         except pickle.PickleError:\n    444             _log.warning(\"Could not pickle model, sampling singlethreaded.\")\n    445             _log.debug('Pickling error:', exec_info=True)\n    446             parallel = False\n\n...........................................................................\nC:\\Users\\Alexander\\Miniconda3\\lib\\site-packages\\pymc3\\sampling.py in _mp_sample(**kwargs={'draws': 6000, 'live_plot': False, 'live_plot_kwargs': None, 'model': <pymc3.model.Model object>, 'njobs': 3, 'step': <pymc3.step_methods.hmc.nuts.NUTS object>, 'trace': None, 'tune': 1000})\n    977             for args in zip(chain_nums, pbars, rseed, start))\n    978 \n    979     if use_mmap:\n    980         traces = Parallel(n_jobs=cores)(jobs)\n    981     else:\n--> 982         traces = Parallel(n_jobs=cores, mmap_mode=None)(jobs)\n        traces = undefined\n        cores = 3\n        jobs = <generator object _mp_sample.<locals>.<genexpr>>\n    983 \n    984     return MultiTrace(traces)\n    985 \n    986 \n\n...........................................................................\nC:\\Users\\Alexander\\Miniconda3\\lib\\site-packages\\joblib\\parallel.py in __call__(self=Parallel(n_jobs=3), iterable=<generator object _mp_sample.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=3)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nMemoryError                                        Fri May 11 21:18:44 2018\nPID: 6440            Python 3.6.5: C:\\Users\\Alexander\\Miniconda3\\python.exe\n...........................................................................\nC:\\Users\\Alexander\\Miniconda3\\lib\\site-packages\\joblib\\parallel.py in __call__(self=<joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _sample>, (0, True, 701098618, {'means': array([ -4.62466574e-01,  -1.98349626e-01,   7.2...e+00,   4.53284820e-01,\n         2.34009797e-01]), 'packed_chol_cholesky_cov_packed__': array([-0.68384149, -0.02451297,  0.89029789, ..., -0.95576035,\n        0.00829716,  0.44670675])}), {'draws': 6000, 'live_plot': False, 'live_plot_kwargs': None, 'model': <pymc3.model.Model object>, 'njobs': 3, 'step': <pymc3.step_methods.hmc.nuts.NUTS object>, 'trace': None, 'tune': 1000})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Alexander\\Miniconda3\\lib\\site-packages\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _sample>\n        args = (0, True, 701098618, {'means': array([ -4.62466574e-01,  -1.98349626e-01,   7.2...e+00,   4.53284820e-01,\n         2.34009797e-01]), 'packed_chol_cholesky_cov_packed__': array([-0.68384149, -0.02451297,  0.89029789, ..., -0.95576035,\n        0.00829716,  0.44670675])})\n        kwargs = {'draws': 6000, 'live_plot': False, 'live_plot_kwargs': None, 'model': <pymc3.model.Model object>, 'njobs': 3, 'step': <pymc3.step_methods.hmc.nuts.NUTS object>, 'trace': None, 'tune': 1000}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Alexander\\Miniconda3\\lib\\site-packages\\pymc3\\sampling.py in _sample(chain=0, progressbar=True, random_seed=701098618, start={'means': array([ -4.62466574e-01,  -1.98349626e-01,   7.2...e+00,   4.53284820e-01,\n         2.34009797e-01]), 'packed_chol_cholesky_cov_packed__': array([-0.68384149, -0.02451297,  0.89029789, ..., -0.95576035,\n        0.00829716,  0.44670675])}, draws=6000, step=<pymc3.step_methods.hmc.nuts.NUTS object>, trace=None, tune=1000, model=<pymc3.model.Model object>, live_plot=False, live_plot_kwargs=None, **kwargs={'njobs': 3})\n    549                             tune, model, random_seed)\n    550     if progressbar:\n    551         sampling = tqdm(sampling, total=draws)\n    552     try:\n    553         strace = None\n--> 554         for it, strace in enumerate(sampling):\n        it = undefined\n        strace = None\n        sampling =   0%|          | 0/6000 [00:02<?, ?it/s]\n    555             if live_plot:\n    556                 if live_plot_kwargs is None:\n    557                     live_plot_kwargs = {}\n    558                 if it >= skip_first:\n\n...........................................................................\nC:\\Users\\Alexander\\Miniconda3\\lib\\site-packages\\tqdm\\_tqdm.py in __iter__(self=  0%|          | 0/6000 [00:02<?, ?it/s])\n    936             except AttributeError:\n    937                 raise TqdmDeprecationWarning(\"\"\"\\\n    938 Please use `tqdm_gui(...)` instead of `tqdm(..., gui=True)`\n    939 \"\"\", fp_write=getattr(self.fp, 'write', sys.stderr.write))\n    940 \n--> 941             for obj in iterable:\n        obj = undefined\n        iterable = <generator object _iter_sample>\n    942                 yield obj\n    943                 # Update and possibly print the progressbar.\n    944                 # Note: does not call self.update(1) for speed optimisation.\n    945                 n += 1\n\n...........................................................................\nC:\\Users\\Alexander\\Miniconda3\\lib\\site-packages\\pymc3\\sampling.py in _iter_sample(draws=6000, step=<pymc3.step_methods.hmc.nuts.NUTS object>, start={'means': array([ -4.62466574e-01,  -1.98349626e-01,   7.2...e+00,   4.53284820e-01,\n         2.34009797e-01]), 'packed_chol_cholesky_cov_packed__': array([-0.68384149, -0.02451297,  0.89029789, ..., -0.95576035,\n        0.00829716,  0.44670675])}, trace=None, chain=0, tune=1000, model=<pymc3.model.Model object>, random_seed=701098618)\n    637         pass\n    638 \n    639     point = Point(start, model=model)\n    640 \n    641     if step.generates_stats and strace.supports_sampler_stats:\n--> 642         strace.setup(draws, chain, step.stats_dtypes)\n        strace.setup = <bound method NDArray.setup of <pymc3.backends.ndarray.NDArray object>>\n        draws = 6000\n        chain = 0\n        step.stats_dtypes = [{'depth': <class 'numpy.int64'>, 'diverging': <class 'bool'>, 'energy': <class 'numpy.float64'>, 'energy_error': <class 'numpy.float64'>, 'max_energy_error': <class 'numpy.float64'>, 'mean_tree_accept': <class 'numpy.float64'>, 'step_size': <class 'numpy.float64'>, 'step_size_bar': <class 'numpy.float64'>, 'tree_size': <class 'numpy.float64'>, 'tune': <class 'bool'>}]\n    643     else:\n    644         strace.setup(draws, chain)\n    645 \n    646     try:\n\n...........................................................................\nC:\\Users\\Alexander\\Miniconda3\\lib\\site-packages\\pymc3\\backends\\ndarray.py in setup(self=<pymc3.backends.ndarray.NDArray object>, draws=6000, chain=0, sampler_vars=[{'depth': <class 'numpy.int64'>, 'diverging': <class 'bool'>, 'energy': <class 'numpy.float64'>, 'energy_error': <class 'numpy.float64'>, 'max_energy_error': <class 'numpy.float64'>, 'mean_tree_accept': <class 'numpy.float64'>, 'step_size': <class 'numpy.float64'>, 'step_size_bar': <class 'numpy.float64'>, 'tree_size': <class 'numpy.float64'>, 'tune': <class 'bool'>}])\n     60                                                        axis=0)\n     61         else:  # Otherwise, make array of zeros for each variable.\n     62             self.draws = draws\n     63             for varname, shape in self.var_shapes.items():\n     64                 self.samples[varname] = np.zeros((draws, ) + shape,\n---> 65                                                  dtype=self.var_dtypes[varname])\n        dtype = undefined\n        self.var_dtypes = {'cov': dtype('float64'), 'means': dtype('float64'), 'packed_chol': dtype('float64'), 'packed_chol_cholesky_cov_packed__': dtype('float64'), 'sigma': dtype('float64')}\n        varname = 'packed_chol'\n     66 \n     67         if sampler_vars is None:\n     68             return\n     69 \n\nMemoryError: \n___________________________________________________________________________",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\Users\\Alexander\\Miniconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 350, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\Users\\Alexander\\Miniconda3\\lib\\site-packages\\joblib\\parallel.py\", line 131, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"C:\\Users\\Alexander\\Miniconda3\\lib\\site-packages\\joblib\\parallel.py\", line 131, in <listcomp>\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"C:\\Users\\Alexander\\Miniconda3\\lib\\site-packages\\pymc3\\sampling.py\", line 554, in _sample\n    for it, strace in enumerate(sampling):\n  File \"C:\\Users\\Alexander\\Miniconda3\\lib\\site-packages\\tqdm\\_tqdm.py\", line 941, in __iter__\n    for obj in iterable:\n  File \"C:\\Users\\Alexander\\Miniconda3\\lib\\site-packages\\pymc3\\sampling.py\", line 642, in _iter_sample\n    strace.setup(draws, chain, step.stats_dtypes)\n  File \"C:\\Users\\Alexander\\Miniconda3\\lib\\site-packages\\pymc3\\backends\\ndarray.py\", line 65, in setup\n    dtype=self.var_dtypes[varname])\nMemoryError\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"C:\\Users\\Alexander\\Miniconda3\\lib\\multiprocessing\\pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"C:\\Users\\Alexander\\Miniconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 359, in __call__\n    raise TransportableException(text, e_type)\njoblib.my_exceptions.TransportableException: TransportableException\n___________________________________________________________________________\nMemoryError                                        Fri May 11 21:18:44 2018\nPID: 6440            Python 3.6.5: C:\\Users\\Alexander\\Miniconda3\\python.exe\n...........................................................................\nC:\\Users\\Alexander\\Miniconda3\\lib\\site-packages\\joblib\\parallel.py in __call__(self=<joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _sample>, (0, True, 701098618, {'means': array([ -4.62466574e-01,  -1.98349626e-01,   7.2...e+00,   4.53284820e-01,\n         2.34009797e-01]), 'packed_chol_cholesky_cov_packed__': array([-0.68384149, -0.02451297,  0.89029789, ..., -0.95576035,\n        0.00829716,  0.44670675])}), {'draws': 6000, 'live_plot': False, 'live_plot_kwargs': None, 'model': <pymc3.model.Model object>, 'njobs': 3, 'step': <pymc3.step_methods.hmc.nuts.NUTS object>, 'trace': None, 'tune': 1000})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Alexander\\Miniconda3\\lib\\site-packages\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _sample>\n        args = (0, True, 701098618, {'means': array([ -4.62466574e-01,  -1.98349626e-01,   7.2...e+00,   4.53284820e-01,\n         2.34009797e-01]), 'packed_chol_cholesky_cov_packed__': array([-0.68384149, -0.02451297,  0.89029789, ..., -0.95576035,\n        0.00829716,  0.44670675])})\n        kwargs = {'draws': 6000, 'live_plot': False, 'live_plot_kwargs': None, 'model': <pymc3.model.Model object>, 'njobs': 3, 'step': <pymc3.step_methods.hmc.nuts.NUTS object>, 'trace': None, 'tune': 1000}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Alexander\\Miniconda3\\lib\\site-packages\\pymc3\\sampling.py in _sample(chain=0, progressbar=True, random_seed=701098618, start={'means': array([ -4.62466574e-01,  -1.98349626e-01,   7.2...e+00,   4.53284820e-01,\n         2.34009797e-01]), 'packed_chol_cholesky_cov_packed__': array([-0.68384149, -0.02451297,  0.89029789, ..., -0.95576035,\n        0.00829716,  0.44670675])}, draws=6000, step=<pymc3.step_methods.hmc.nuts.NUTS object>, trace=None, tune=1000, model=<pymc3.model.Model object>, live_plot=False, live_plot_kwargs=None, **kwargs={'njobs': 3})\n    549                             tune, model, random_seed)\n    550     if progressbar:\n    551         sampling = tqdm(sampling, total=draws)\n    552     try:\n    553         strace = None\n--> 554         for it, strace in enumerate(sampling):\n        it = undefined\n        strace = None\n        sampling =   0%|          | 0/6000 [00:02<?, ?it/s]\n    555             if live_plot:\n    556                 if live_plot_kwargs is None:\n    557                     live_plot_kwargs = {}\n    558                 if it >= skip_first:\n\n...........................................................................\nC:\\Users\\Alexander\\Miniconda3\\lib\\site-packages\\tqdm\\_tqdm.py in __iter__(self=  0%|          | 0/6000 [00:02<?, ?it/s])\n    936             except AttributeError:\n    937                 raise TqdmDeprecationWarning(\"\"\"\\\n    938 Please use `tqdm_gui(...)` instead of `tqdm(..., gui=True)`\n    939 \"\"\", fp_write=getattr(self.fp, 'write', sys.stderr.write))\n    940 \n--> 941             for obj in iterable:\n        obj = undefined\n        iterable = <generator object _iter_sample>\n    942                 yield obj\n    943                 # Update and possibly print the progressbar.\n    944                 # Note: does not call self.update(1) for speed optimisation.\n    945                 n += 1\n\n...........................................................................\nC:\\Users\\Alexander\\Miniconda3\\lib\\site-packages\\pymc3\\sampling.py in _iter_sample(draws=6000, step=<pymc3.step_methods.hmc.nuts.NUTS object>, start={'means': array([ -4.62466574e-01,  -1.98349626e-01,   7.2...e+00,   4.53284820e-01,\n         2.34009797e-01]), 'packed_chol_cholesky_cov_packed__': array([-0.68384149, -0.02451297,  0.89029789, ..., -0.95576035,\n        0.00829716,  0.44670675])}, trace=None, chain=0, tune=1000, model=<pymc3.model.Model object>, random_seed=701098618)\n    637         pass\n    638 \n    639     point = Point(start, model=model)\n    640 \n    641     if step.generates_stats and strace.supports_sampler_stats:\n--> 642         strace.setup(draws, chain, step.stats_dtypes)\n        strace.setup = <bound method NDArray.setup of <pymc3.backends.ndarray.NDArray object>>\n        draws = 6000\n        chain = 0\n        step.stats_dtypes = [{'depth': <class 'numpy.int64'>, 'diverging': <class 'bool'>, 'energy': <class 'numpy.float64'>, 'energy_error': <class 'numpy.float64'>, 'max_energy_error': <class 'numpy.float64'>, 'mean_tree_accept': <class 'numpy.float64'>, 'step_size': <class 'numpy.float64'>, 'step_size_bar': <class 'numpy.float64'>, 'tree_size': <class 'numpy.float64'>, 'tune': <class 'bool'>}]\n    643     else:\n    644         strace.setup(draws, chain)\n    645 \n    646     try:\n\n...........................................................................\nC:\\Users\\Alexander\\Miniconda3\\lib\\site-packages\\pymc3\\backends\\ndarray.py in setup(self=<pymc3.backends.ndarray.NDArray object>, draws=6000, chain=0, sampler_vars=[{'depth': <class 'numpy.int64'>, 'diverging': <class 'bool'>, 'energy': <class 'numpy.float64'>, 'energy_error': <class 'numpy.float64'>, 'max_energy_error': <class 'numpy.float64'>, 'mean_tree_accept': <class 'numpy.float64'>, 'step_size': <class 'numpy.float64'>, 'step_size_bar': <class 'numpy.float64'>, 'tree_size': <class 'numpy.float64'>, 'tune': <class 'bool'>}])\n     60                                                        axis=0)\n     61         else:  # Otherwise, make array of zeros for each variable.\n     62             self.draws = draws\n     63             for varname, shape in self.var_shapes.items():\n     64                 self.samples[varname] = np.zeros((draws, ) + shape,\n---> 65                                                  dtype=self.var_dtypes[varname])\n        dtype = undefined\n        self.var_dtypes = {'cov': dtype('float64'), 'means': dtype('float64'), 'packed_chol': dtype('float64'), 'packed_chol_cholesky_cov_packed__': dtype('float64'), 'sigma': dtype('float64')}\n        varname = 'packed_chol'\n     66 \n     67         if sampler_vars is None:\n     68             return\n     69 \n\nMemoryError: \n___________________________________________________________________________\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mTransportableException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    698\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 699\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    700\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    643\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 644\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    645\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTransportableException\u001b[0m: TransportableException\n___________________________________________________________________________\nMemoryError                                        Fri May 11 21:18:44 2018\nPID: 6440            Python 3.6.5: C:\\Users\\Alexander\\Miniconda3\\python.exe\n...........................................................................\nC:\\Users\\Alexander\\Miniconda3\\lib\\site-packages\\joblib\\parallel.py in __call__(self=<joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _sample>, (0, True, 701098618, {'means': array([ -4.62466574e-01,  -1.98349626e-01,   7.2...e+00,   4.53284820e-01,\n         2.34009797e-01]), 'packed_chol_cholesky_cov_packed__': array([-0.68384149, -0.02451297,  0.89029789, ..., -0.95576035,\n        0.00829716,  0.44670675])}), {'draws': 6000, 'live_plot': False, 'live_plot_kwargs': None, 'model': <pymc3.model.Model object>, 'njobs': 3, 'step': <pymc3.step_methods.hmc.nuts.NUTS object>, 'trace': None, 'tune': 1000})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Alexander\\Miniconda3\\lib\\site-packages\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _sample>\n        args = (0, True, 701098618, {'means': array([ -4.62466574e-01,  -1.98349626e-01,   7.2...e+00,   4.53284820e-01,\n         2.34009797e-01]), 'packed_chol_cholesky_cov_packed__': array([-0.68384149, -0.02451297,  0.89029789, ..., -0.95576035,\n        0.00829716,  0.44670675])})\n        kwargs = {'draws': 6000, 'live_plot': False, 'live_plot_kwargs': None, 'model': <pymc3.model.Model object>, 'njobs': 3, 'step': <pymc3.step_methods.hmc.nuts.NUTS object>, 'trace': None, 'tune': 1000}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Alexander\\Miniconda3\\lib\\site-packages\\pymc3\\sampling.py in _sample(chain=0, progressbar=True, random_seed=701098618, start={'means': array([ -4.62466574e-01,  -1.98349626e-01,   7.2...e+00,   4.53284820e-01,\n         2.34009797e-01]), 'packed_chol_cholesky_cov_packed__': array([-0.68384149, -0.02451297,  0.89029789, ..., -0.95576035,\n        0.00829716,  0.44670675])}, draws=6000, step=<pymc3.step_methods.hmc.nuts.NUTS object>, trace=None, tune=1000, model=<pymc3.model.Model object>, live_plot=False, live_plot_kwargs=None, **kwargs={'njobs': 3})\n    549                             tune, model, random_seed)\n    550     if progressbar:\n    551         sampling = tqdm(sampling, total=draws)\n    552     try:\n    553         strace = None\n--> 554         for it, strace in enumerate(sampling):\n        it = undefined\n        strace = None\n        sampling =   0%|          | 0/6000 [00:02<?, ?it/s]\n    555             if live_plot:\n    556                 if live_plot_kwargs is None:\n    557                     live_plot_kwargs = {}\n    558                 if it >= skip_first:\n\n...........................................................................\nC:\\Users\\Alexander\\Miniconda3\\lib\\site-packages\\tqdm\\_tqdm.py in __iter__(self=  0%|          | 0/6000 [00:02<?, ?it/s])\n    936             except AttributeError:\n    937                 raise TqdmDeprecationWarning(\"\"\"\\\n    938 Please use `tqdm_gui(...)` instead of `tqdm(..., gui=True)`\n    939 \"\"\", fp_write=getattr(self.fp, 'write', sys.stderr.write))\n    940 \n--> 941             for obj in iterable:\n        obj = undefined\n        iterable = <generator object _iter_sample>\n    942                 yield obj\n    943                 # Update and possibly print the progressbar.\n    944                 # Note: does not call self.update(1) for speed optimisation.\n    945                 n += 1\n\n...........................................................................\nC:\\Users\\Alexander\\Miniconda3\\lib\\site-packages\\pymc3\\sampling.py in _iter_sample(draws=6000, step=<pymc3.step_methods.hmc.nuts.NUTS object>, start={'means': array([ -4.62466574e-01,  -1.98349626e-01,   7.2...e+00,   4.53284820e-01,\n         2.34009797e-01]), 'packed_chol_cholesky_cov_packed__': array([-0.68384149, -0.02451297,  0.89029789, ..., -0.95576035,\n        0.00829716,  0.44670675])}, trace=None, chain=0, tune=1000, model=<pymc3.model.Model object>, random_seed=701098618)\n    637         pass\n    638 \n    639     point = Point(start, model=model)\n    640 \n    641     if step.generates_stats and strace.supports_sampler_stats:\n--> 642         strace.setup(draws, chain, step.stats_dtypes)\n        strace.setup = <bound method NDArray.setup of <pymc3.backends.ndarray.NDArray object>>\n        draws = 6000\n        chain = 0\n        step.stats_dtypes = [{'depth': <class 'numpy.int64'>, 'diverging': <class 'bool'>, 'energy': <class 'numpy.float64'>, 'energy_error': <class 'numpy.float64'>, 'max_energy_error': <class 'numpy.float64'>, 'mean_tree_accept': <class 'numpy.float64'>, 'step_size': <class 'numpy.float64'>, 'step_size_bar': <class 'numpy.float64'>, 'tree_size': <class 'numpy.float64'>, 'tune': <class 'bool'>}]\n    643     else:\n    644         strace.setup(draws, chain)\n    645 \n    646     try:\n\n...........................................................................\nC:\\Users\\Alexander\\Miniconda3\\lib\\site-packages\\pymc3\\backends\\ndarray.py in setup(self=<pymc3.backends.ndarray.NDArray object>, draws=6000, chain=0, sampler_vars=[{'depth': <class 'numpy.int64'>, 'diverging': <class 'bool'>, 'energy': <class 'numpy.float64'>, 'energy_error': <class 'numpy.float64'>, 'max_energy_error': <class 'numpy.float64'>, 'mean_tree_accept': <class 'numpy.float64'>, 'step_size': <class 'numpy.float64'>, 'step_size_bar': <class 'numpy.float64'>, 'tree_size': <class 'numpy.float64'>, 'tune': <class 'bool'>}])\n     60                                                        axis=0)\n     61         else:  # Otherwise, make array of zeros for each variable.\n     62             self.draws = draws\n     63             for varname, shape in self.var_shapes.items():\n     64                 self.samples[varname] = np.zeros((draws, ) + shape,\n---> 65                                                  dtype=self.var_dtypes[varname])\n        dtype = undefined\n        self.var_dtypes = {'cov': dtype('float64'), 'means': dtype('float64'), 'packed_chol': dtype('float64'), 'packed_chol_cholesky_cov_packed__': dtype('float64'), 'sigma': dtype('float64')}\n        varname = 'packed_chol'\n     66 \n     67         if sampler_vars is None:\n     68             return\n     69 \n\nMemoryError: \n___________________________________________________________________________",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mJoblibMemoryError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-189-7f2adb20e97e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mtrace\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtune\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdraws\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnjobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcores\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\pymc3\\sampling.py\u001b[0m in \u001b[0;36msample\u001b[1;34m(draws, step, init, n_init, start, trace, chain_idx, chains, cores, tune, nuts_kwargs, step_kwargs, progressbar, model, random_seed, live_plot, discard_tuned_samples, live_plot_kwargs, compute_convergence_checks, use_mmap, **kwargs)\u001b[0m\n\u001b[0;32m    440\u001b[0m         \u001b[0m_print_step_hierarchy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    441\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 442\u001b[1;33m             \u001b[0mtrace\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_mp_sample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0msample_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    443\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPickleError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    444\u001b[0m             \u001b[0m_log\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Could not pickle model, sampling singlethreaded.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\pymc3\\sampling.py\u001b[0m in \u001b[0;36m_mp_sample\u001b[1;34m(**kwargs)\u001b[0m\n\u001b[0;32m    980\u001b[0m         \u001b[0mtraces\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mParallel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    981\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 982\u001b[1;33m         \u001b[0mtraces\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mParallel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmmap_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    983\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    984\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mMultiTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraces\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    787\u001b[0m                 \u001b[1;31m# consumption.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 789\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    790\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    738\u001b[0m                     \u001b[0mexception\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexception_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    739\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 740\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    742\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mJoblibMemoryError\u001b[0m: JoblibMemoryError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\nC:\\Users\\Alexander\\Miniconda3\\lib\\runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\nC:\\Users\\Alexander\\Miniconda3\\lib\\runpy.py in _run_code(code=<code object <module> at 0x000000F6A7387030, fil...lib\\site-packages\\ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\Users\\Alexander\\Miniconda3\\lib\\site-packages\\__pycache__\\ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\Users\\Alexander\\Miniconda3\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\Users\\\\A...a3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x000000F6A7387030, fil...lib\\site-packages\\ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\Users\\Alexander\\Miniconda3\\lib\\site-packages\\__pycache__\\ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\Users\\Alexander\\Miniconda3\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\Users\\\\A...a3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\nC:\\Users\\Alexander\\Miniconda3\\lib\\site-packages\\ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\nC:\\Users\\Alexander\\Miniconda3\\lib\\site-packages\\traitlets\\config\\application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\nC:\\Users\\Alexander\\Miniconda3\\lib\\site-packages\\ipykernel\\kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    481         if self.poller is not None:\n    482             self.poller.start()\n    483         self.kernel.start()\n    484         self.io_loop = ioloop.IOLoop.current()\n    485         try:\n--> 486             self.io_loop.start()\n        self.io_loop.start = <bound method BaseAsyncIOLoop.start of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n    487         except KeyboardInterrupt:\n    488             pass\n    489 \n    490 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\nC:\\Users\\Alexander\\Miniconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py in start(self=<tornado.platform.asyncio.AsyncIOMainLoop object>)\n    122         except (RuntimeError, AssertionError):\n    123             old_loop = None\n    124         try:\n    125             self._setup_logging()\n    126             asyncio.set_event_loop(self.asyncio_loop)\n--> 127             self.asyncio_loop.run_forever()\n        self.asyncio_loop.run_forever = <bound method BaseEventLoop.run_forever of <_Win...EventLoop running=True closed=False debug=False>>\n    128         finally:\n    129             asyncio.set_event_loop(old_loop)\n    130 \n    131     def stop(self):\n\n...........................................................................\nC:\\Users\\Alexander\\Miniconda3\\lib\\asyncio\\base_events.py in run_forever(self=<_WindowsSelectorEventLoop running=True closed=False debug=False>)\n    417             sys.set_asyncgen_hooks(firstiter=self._asyncgen_firstiter_hook,\n    418                                    finalizer=self._asyncgen_finalizer_hook)\n    419         try:\n    420             events._set_running_loop(self)\n    421             while True:\n--> 422                 self._run_once()\n        self._run_once = <bound method BaseEventLoop._run_once of <_Windo...EventLoop running=True closed=False debug=False>>\n    423                 if self._stopping:\n    424                     break\n    425         finally:\n    426             self._stopping = False\n\n...........................................................................\nC:\\Users\\Alexander\\Miniconda3\\lib\\asyncio\\base_events.py in _run_once(self=<_WindowsSelectorEventLoop running=True closed=False debug=False>)\n   1427                         logger.warning('Executing %s took %.3f seconds',\n   1428                                        _format_handle(handle), dt)\n   1429                 finally:\n   1430                     self._current_handle = None\n   1431             else:\n-> 1432                 handle._run()\n        handle._run = <bound method Handle._run of <Handle IOLoop._run_callback(functools.par...00F6B46B5268>))>>\n   1433         handle = None  # Needed to break cycles when an exception occurs.\n   1434 \n   1435     def _set_coroutine_wrapper(self, enabled):\n   1436         try:\n\n...........................................................................\nC:\\Users\\Alexander\\Miniconda3\\lib\\asyncio\\events.py in _run(self=<Handle IOLoop._run_callback(functools.par...00F6B46B5268>))>)\n    140             self._callback = None\n    141             self._args = None\n    142 \n    143     def _run(self):\n    144         try:\n--> 145             self._callback(*self._args)\n        self._callback = <bound method IOLoop._run_callback of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n        self._args = (functools.partial(<function wrap.<locals>.null_wrapper at 0x000000F6B46B5268>),)\n    146         except Exception as exc:\n    147             cb = _format_callback_source(self._callback, self._args)\n    148             msg = 'Exception in callback {}'.format(cb)\n    149             context = {\n\n...........................................................................\nC:\\Users\\Alexander\\Miniconda3\\lib\\site-packages\\tornado\\ioloop.py in _run_callback(self=<tornado.platform.asyncio.AsyncIOMainLoop object>, callback=functools.partial(<function wrap.<locals>.null_wrapper at 0x000000F6B46B5268>))\n    754         \"\"\"Runs a callback with error handling.\n    755 \n    756         For use in subclasses.\n    757         \"\"\"\n    758         try:\n--> 759             ret = callback()\n        ret = undefined\n        callback = functools.partial(<function wrap.<locals>.null_wrapper at 0x000000F6B46B5268>)\n    760             if ret is not None:\n    761                 from tornado import gen\n    762                 # Functions that return Futures typically swallow all\n    763                 # exceptions and store them in the Future.  If a Future\n\n...........................................................................\nC:\\Users\\Alexander\\Miniconda3\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=(), **kwargs={})\n    271         # Fast path when there are no active contexts.\n    272         def null_wrapper(*args, **kwargs):\n    273             try:\n    274                 current_state = _state.contexts\n    275                 _state.contexts = cap_contexts[0]\n--> 276                 return fn(*args, **kwargs)\n        args = ()\n        kwargs = {}\n    277             finally:\n    278                 _state.contexts = current_state\n    279         null_wrapper._wrapped = True\n    280         return null_wrapper\n\n...........................................................................\nC:\\Users\\Alexander\\Miniconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in <lambda>()\n    531             return\n    532 \n    533         if state & self.socket.events:\n    534             # events still exist that haven't been processed\n    535             # explicitly schedule handling to avoid missing events due to edge-triggered FDs\n--> 536             self.io_loop.add_callback(lambda : self._handle_events(self.socket, 0))\n    537 \n    538     def _init_io_state(self):\n    539         \"\"\"initialize the ioloop event handler\"\"\"\n    540         with stack_context.NullContext():\n\n...........................................................................\nC:\\Users\\Alexander\\Miniconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=0)\n    445             return\n    446         zmq_events = self.socket.EVENTS\n    447         try:\n    448             # dispatch events:\n    449             if zmq_events & zmq.POLLIN and self.receiving():\n--> 450                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    451                 if not self.socket:\n    452                     return\n    453             if zmq_events & zmq.POLLOUT and self.sending():\n    454                 self._handle_send()\n\n...........................................................................\nC:\\Users\\Alexander\\Miniconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    475             else:\n    476                 raise\n    477         else:\n    478             if self._recv_callback:\n    479                 callback = self._recv_callback\n--> 480                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    481         \n    482 \n    483     def _handle_send(self):\n    484         \"\"\"Handle a send event.\"\"\"\n\n...........................................................................\nC:\\Users\\Alexander\\Miniconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    427         close our socket.\"\"\"\n    428         try:\n    429             # Use a NullContext to ensure that all StackContexts are run\n    430             # inside our blanket exception handler rather than outside.\n    431             with stack_context.NullContext():\n--> 432                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    433         except:\n    434             gen_log.error(\"Uncaught exception in ZMQStream callback\",\n    435                           exc_info=True)\n    436             # Re-raise the exception so that IOLoop.handle_callback_exception\n\n...........................................................................\nC:\\Users\\Alexander\\Miniconda3\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    271         # Fast path when there are no active contexts.\n    272         def null_wrapper(*args, **kwargs):\n    273             try:\n    274                 current_state = _state.contexts\n    275                 _state.contexts = cap_contexts[0]\n--> 276                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    277             finally:\n    278                 _state.contexts = current_state\n    279         null_wrapper._wrapped = True\n    280         return null_wrapper\n\n...........................................................................\nC:\\Users\\Alexander\\Miniconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\nC:\\Users\\Alexander\\Miniconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': 'with model:\\n    trace = pm.sample(tune=1000, draws=5000, njobs=3, cores=3)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 5, 12, 1, 18, 29, 703076, tzinfo=tzutc()), 'msg_id': 'aa95a188ac3d4ec08b465d8804041749', 'msg_type': 'execute_request', 'session': '9c3da7d992cc47ad83ff17e0afaa95be', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'aa95a188ac3d4ec08b465d8804041749', 'msg_type': 'execute_request', 'parent_header': {}})\n    228             self.log.warn(\"Unknown message type: %r\", msg_type)\n    229         else:\n    230             self.log.debug(\"%s: %s\", msg_type, msg)\n    231             self.pre_handler_hook()\n    232             try:\n--> 233                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'9c3da7d992cc47ad83ff17e0afaa95be']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': 'with model:\\n    trace = pm.sample(tune=1000, draws=5000, njobs=3, cores=3)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 5, 12, 1, 18, 29, 703076, tzinfo=tzutc()), 'msg_id': 'aa95a188ac3d4ec08b465d8804041749', 'msg_type': 'execute_request', 'session': '9c3da7d992cc47ad83ff17e0afaa95be', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'aa95a188ac3d4ec08b465d8804041749', 'msg_type': 'execute_request', 'parent_header': {}}\n    234             except Exception:\n    235                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    236             finally:\n    237                 self.post_handler_hook()\n\n...........................................................................\nC:\\Users\\Alexander\\Miniconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'9c3da7d992cc47ad83ff17e0afaa95be'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': 'with model:\\n    trace = pm.sample(tune=1000, draws=5000, njobs=3, cores=3)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 5, 12, 1, 18, 29, 703076, tzinfo=tzutc()), 'msg_id': 'aa95a188ac3d4ec08b465d8804041749', 'msg_type': 'execute_request', 'session': '9c3da7d992cc47ad83ff17e0afaa95be', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'aa95a188ac3d4ec08b465d8804041749', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\nC:\\Users\\Alexander\\Miniconda3\\lib\\site-packages\\ipykernel\\ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='with model:\\n    trace = pm.sample(tune=1000, draws=5000, njobs=3, cores=3)', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    203 \n    204         self._forward_input(allow_stdin)\n    205 \n    206         reply_content = {}\n    207         try:\n--> 208             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = 'with model:\\n    trace = pm.sample(tune=1000, draws=5000, njobs=3, cores=3)'\n        store_history = True\n        silent = False\n    209         finally:\n    210             self._restore_input()\n    211 \n    212         if res.error_before_exec is not None:\n\n...........................................................................\nC:\\Users\\Alexander\\Miniconda3\\lib\\site-packages\\ipykernel\\zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=('with model:\\n    trace = pm.sample(tune=1000, draws=5000, njobs=3, cores=3)',), **kwargs={'silent': False, 'store_history': True})\n    532             )\n    533         self.payload_manager.write_payload(payload)\n    534 \n    535     def run_cell(self, *args, **kwargs):\n    536         self._last_traceback = None\n--> 537         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = ('with model:\\n    trace = pm.sample(tune=1000, draws=5000, njobs=3, cores=3)',)\n        kwargs = {'silent': False, 'store_history': True}\n    538 \n    539     def _showtraceback(self, etype, evalue, stb):\n    540         # try to preserve ordering of tracebacks and print statements\n    541         sys.stdout.flush()\n\n...........................................................................\nC:\\Users\\Alexander\\Miniconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='with model:\\n    trace = pm.sample(tune=1000, draws=5000, njobs=3, cores=3)', store_history=True, silent=False, shell_futures=True)\n   2657         -------\n   2658         result : :class:`ExecutionResult`\n   2659         \"\"\"\n   2660         try:\n   2661             result = self._run_cell(\n-> 2662                 raw_cell, store_history, silent, shell_futures)\n        raw_cell = 'with model:\\n    trace = pm.sample(tune=1000, draws=5000, njobs=3, cores=3)'\n        store_history = True\n        silent = False\n        shell_futures = True\n   2663         finally:\n   2664             self.events.trigger('post_execute')\n   2665             if not silent:\n   2666                 self.events.trigger('post_run_cell', result)\n\n...........................................................................\nC:\\Users\\Alexander\\Miniconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in _run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='with model:\\n    trace = pm.sample(tune=1000, draws=5000, njobs=3, cores=3)', store_history=True, silent=False, shell_futures=True)\n   2780                 self.displayhook.exec_result = result\n   2781 \n   2782                 # Execute the user code\n   2783                 interactivity = 'none' if silent else self.ast_node_interactivity\n   2784                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2785                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2786                 \n   2787                 self.last_execution_succeeded = not has_raised\n   2788                 self.last_execution_result = result\n   2789 \n\n...........................................................................\nC:\\Users\\Alexander\\Miniconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.With object>], cell_name='<ipython-input-189-7f2adb20e97e>', interactivity='none', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at f6b240a7b8, execution...rue silent=False shell_futures=True> result=None>)\n   2898 \n   2899         try:\n   2900             for i, node in enumerate(to_run_exec):\n   2901                 mod = ast.Module([node])\n   2902                 code = compiler(mod, cell_name, \"exec\")\n-> 2903                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x000000F6B026EDB0, file \"<ipython-input-189-7f2adb20e97e>\", line 1>\n        result = <ExecutionResult object at f6b240a7b8, execution...rue silent=False shell_futures=True> result=None>\n   2904                     return True\n   2905 \n   2906             for i, node in enumerate(to_run_interactive):\n   2907                 mod = ast.Interactive([node])\n\n...........................................................................\nC:\\Users\\Alexander\\Miniconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x000000F6B026EDB0, file \"<ipython-input-189-7f2adb20e97e>\", line 1>, result=<ExecutionResult object at f6b240a7b8, execution...rue silent=False shell_futures=True> result=None>)\n   2958         outflag = True  # happens in more places, so it's easier as default\n   2959         try:\n   2960             try:\n   2961                 self.hooks.pre_run_code_hook()\n   2962                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2963                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x000000F6B026EDB0, file \"<ipython-input-189-7f2adb20e97e>\", line 1>\n        self.user_global_ns = {'In': ['', \"import warnings\\nwarnings.simplefilter(action='ig...cov, cov2corr\\nimport h5py\\nimport dask.array as da\", '# opening a file handle\\nwith h5py.File(\"db.h5\", ...nk+chunks, :] = data\\n        \\n    bigdata.close()', '# opening a file handle\\nwith h5py.File(\"db.h5\", ...nk+chunks, :] = data\\n        \\n    bigdata.close()', \"import warnings\\nwarnings.simplefilter(action='ig...cov, cov2corr\\nimport h5py\\nimport dask.array as da\", '# opening a file handle\\nwith h5py.File(\"db.h5\", ...nk+chunks, :] = data\\n        \\n    bigdata.close()', '# opening a file handle\\nwith h5py.File(\"db.h5\", ...nk+chunks, :] = data\\n        \\n    bigdata.close()', '# opening a file handle\\nwith h5py.File(\"db.h5\", ...nk+chunks, :] = data\\n        \\n    bigdata.close()', '# opening a file handle\\nwith h5py.File(\"db.h5\", ...nk+chunks, :] = data\\n        \\n    bigdata.close()', '# opening a file handle\\nwith h5py.File(\"db.h5\", ...nk+chunks, :] = data\\n        \\n    bigdata.close()', 'for chunk in range(x, totrows, chunks)\\n    print(chunk)', 'for chunk in range(x, totrows, chunks):\\n    print(chunk)', '# opening a file handle\\nwith h5py.File(\"db.h5\", ...nk+chunks, :] = data\\n        \\n    bigdata.close()', '# opening a file handle\\nwith h5py.File(\"db.h5\", ...nk+chunks, :] = data\\n        \\n    bigdata.close()', '# opening a file handle\\nwith h5py.File(\"db.h5\", ...nk+chunks, :] = data\\n        \\n    bigdata.close()', 'for chunk in range(x, totrows, chunks):\\n    print(chunk)', 'for chunk in range(x, nrows, chunks):\\n    print(chunk)', 'for chunk in range(x, nrows, chunks):\\n    print(chunk)', '# opening a file handle\\nwith h5py.File(\"db.h5\", ...nk+chunks, :] = data\\n        \\n    bigdata.close()', 'for chunk in range(x, nrows, chunks):\\n    print(chunk)', ...], 'Out': {28: array([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., ....,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]]), 29: array([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]]), 30: array([ 0.]), 31: array([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., ....,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]]), 32: array([[ 0.,  0.,  0.,  0.],\n       [ 0.,  0.,  ...0.,  0.,  0.,  0.],\n       [ 0.,  0.,  0.,  0.]]), 40: (9, 1), 41:   HN28_P15_D06_S330_comb\n0                      ...7                      0\n8                      0, 42:                        Unnamed: 0\n0      process...        'ELMO2'\n8                       'CREB3L1', 44: ['\\tHN28_P15_D06_S330_comb\\tHN28_P6_G05_S173_comb\\tHN...HNSCC20_P3_H08_S92_comb\\tHNSCC20_P3_G06_S78_comb\\r\\n', 'processed by Maxima enzyme\\t1\\t1\\t1\\t1\\t1\\t1\\t1\\t1\\t1\\t1\\t1...0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\r\\n', 'Lymph node\\t1\\t0\\t1\\t1\\t1\\t1\\t1\\t1\\t1\\t1\\t0\\t1\\t1\\t1\\t0\\t0\\t0\\t0\\t1...1\\t0\\t0\\t0\\t0\\t0\\t1\\t0\\t1\\t1\\t0\\t0\\t1\\t0\\t0\\t1\\t0\\t0\\t0\\t0\\t1\\t0\\t0\\t0\\r\\n', 'classified  as cancer cell\\t0\\t0\\t1\\t0\\t1\\t1\\t1\\t0\\t1\\t1\\t0...1\\t1\\t1\\t1\\t1\\t1\\t1\\t0\\t1\\t1\\t1\\t1\\t1\\t1\\t1\\t1\\t1\\t1\\t1\\t0\\t1\\t1\\t1\\t1\\r\\n', 'classified as non-cancer cells\\t1\\t1\\t0\\t1\\t0\\t0\\t0\\t1\\t0...0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\r\\n', 'non-cancer cell type\\tFibroblast\\tFibroblast\\t0\\tFib...0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\r\\n', \"'C9orf152'\\t0\\t0\\t0.42761\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0...0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\r\\n\", \"'RPS11'\\t6.0037\\t7.3006\\t7.2885\\t0\\t7.4742\\t6.9548\\t5.9....5167\\t7.3249\\t5.3595\\t7.4281\\t6.8439\\t6.8676\\t6.3146\\r\\n\", \"'ELMO2'\\t0\\t0\\t0\\t5.2465\\t0.50487\\t0\\t0\\t3.4154\\t0\\t1.9613...0\\t0\\t0\\t0\\t0\\t0\\t0\\t0.62106\\t0\\t0\\t0\\t0\\t0\\t3.2863\\t0\\t3.5905\\r\\n\", \"'CREB3L1'\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0.71...0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\r\\n\"], 53: (23691, 1), ...}, '_': (10, 454), '_100': [True], '_111': [362, 8618, 20263, 11705, 891, 10, 11796, 18375, 9525, 9971, 9971], '_113': [362, 8618, 20263, 11705, 891, 10, 11796, 18375, 9525, 9971, 9971], '_116': [362, 8618, 20263, 11705, 891, 10, 11796, 18375, 9525, 9971, 21328, 1749], '_118': [362, 8618, 20263, 11705, 891, 10, 11796, 18375, 9525, 9971, 21328, 1749], '_119': [362, 8618, 20263, 11705, 891, 10, 11796, 18375, 9525, 9971, 21328, 1749], '_120': [362, 8618, 20263, 11705, 891, 10, 11796, 18375, 9525, 9971, 21328, 1749], ...}\n        self.user_ns = {'In': ['', \"import warnings\\nwarnings.simplefilter(action='ig...cov, cov2corr\\nimport h5py\\nimport dask.array as da\", '# opening a file handle\\nwith h5py.File(\"db.h5\", ...nk+chunks, :] = data\\n        \\n    bigdata.close()', '# opening a file handle\\nwith h5py.File(\"db.h5\", ...nk+chunks, :] = data\\n        \\n    bigdata.close()', \"import warnings\\nwarnings.simplefilter(action='ig...cov, cov2corr\\nimport h5py\\nimport dask.array as da\", '# opening a file handle\\nwith h5py.File(\"db.h5\", ...nk+chunks, :] = data\\n        \\n    bigdata.close()', '# opening a file handle\\nwith h5py.File(\"db.h5\", ...nk+chunks, :] = data\\n        \\n    bigdata.close()', '# opening a file handle\\nwith h5py.File(\"db.h5\", ...nk+chunks, :] = data\\n        \\n    bigdata.close()', '# opening a file handle\\nwith h5py.File(\"db.h5\", ...nk+chunks, :] = data\\n        \\n    bigdata.close()', '# opening a file handle\\nwith h5py.File(\"db.h5\", ...nk+chunks, :] = data\\n        \\n    bigdata.close()', 'for chunk in range(x, totrows, chunks)\\n    print(chunk)', 'for chunk in range(x, totrows, chunks):\\n    print(chunk)', '# opening a file handle\\nwith h5py.File(\"db.h5\", ...nk+chunks, :] = data\\n        \\n    bigdata.close()', '# opening a file handle\\nwith h5py.File(\"db.h5\", ...nk+chunks, :] = data\\n        \\n    bigdata.close()', '# opening a file handle\\nwith h5py.File(\"db.h5\", ...nk+chunks, :] = data\\n        \\n    bigdata.close()', 'for chunk in range(x, totrows, chunks):\\n    print(chunk)', 'for chunk in range(x, nrows, chunks):\\n    print(chunk)', 'for chunk in range(x, nrows, chunks):\\n    print(chunk)', '# opening a file handle\\nwith h5py.File(\"db.h5\", ...nk+chunks, :] = data\\n        \\n    bigdata.close()', 'for chunk in range(x, nrows, chunks):\\n    print(chunk)', ...], 'Out': {28: array([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., ....,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]]), 29: array([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]]), 30: array([ 0.]), 31: array([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., ....,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]]), 32: array([[ 0.,  0.,  0.,  0.],\n       [ 0.,  0.,  ...0.,  0.,  0.,  0.],\n       [ 0.,  0.,  0.,  0.]]), 40: (9, 1), 41:   HN28_P15_D06_S330_comb\n0                      ...7                      0\n8                      0, 42:                        Unnamed: 0\n0      process...        'ELMO2'\n8                       'CREB3L1', 44: ['\\tHN28_P15_D06_S330_comb\\tHN28_P6_G05_S173_comb\\tHN...HNSCC20_P3_H08_S92_comb\\tHNSCC20_P3_G06_S78_comb\\r\\n', 'processed by Maxima enzyme\\t1\\t1\\t1\\t1\\t1\\t1\\t1\\t1\\t1\\t1\\t1...0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\r\\n', 'Lymph node\\t1\\t0\\t1\\t1\\t1\\t1\\t1\\t1\\t1\\t1\\t0\\t1\\t1\\t1\\t0\\t0\\t0\\t0\\t1...1\\t0\\t0\\t0\\t0\\t0\\t1\\t0\\t1\\t1\\t0\\t0\\t1\\t0\\t0\\t1\\t0\\t0\\t0\\t0\\t1\\t0\\t0\\t0\\r\\n', 'classified  as cancer cell\\t0\\t0\\t1\\t0\\t1\\t1\\t1\\t0\\t1\\t1\\t0...1\\t1\\t1\\t1\\t1\\t1\\t1\\t0\\t1\\t1\\t1\\t1\\t1\\t1\\t1\\t1\\t1\\t1\\t1\\t0\\t1\\t1\\t1\\t1\\r\\n', 'classified as non-cancer cells\\t1\\t1\\t0\\t1\\t0\\t0\\t0\\t1\\t0...0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\r\\n', 'non-cancer cell type\\tFibroblast\\tFibroblast\\t0\\tFib...0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\r\\n', \"'C9orf152'\\t0\\t0\\t0.42761\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0...0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\r\\n\", \"'RPS11'\\t6.0037\\t7.3006\\t7.2885\\t0\\t7.4742\\t6.9548\\t5.9....5167\\t7.3249\\t5.3595\\t7.4281\\t6.8439\\t6.8676\\t6.3146\\r\\n\", \"'ELMO2'\\t0\\t0\\t0\\t5.2465\\t0.50487\\t0\\t0\\t3.4154\\t0\\t1.9613...0\\t0\\t0\\t0\\t0\\t0\\t0\\t0.62106\\t0\\t0\\t0\\t0\\t0\\t3.2863\\t0\\t3.5905\\r\\n\", \"'CREB3L1'\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0.71...0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\r\\n\"], 53: (23691, 1), ...}, '_': (10, 454), '_100': [True], '_111': [362, 8618, 20263, 11705, 891, 10, 11796, 18375, 9525, 9971, 9971], '_113': [362, 8618, 20263, 11705, 891, 10, 11796, 18375, 9525, 9971, 9971], '_116': [362, 8618, 20263, 11705, 891, 10, 11796, 18375, 9525, 9971, 21328, 1749], '_118': [362, 8618, 20263, 11705, 891, 10, 11796, 18375, 9525, 9971, 21328, 1749], '_119': [362, 8618, 20263, 11705, 891, 10, 11796, 18375, 9525, 9971, 21328, 1749], '_120': [362, 8618, 20263, 11705, 891, 10, 11796, 18375, 9525, 9971, 21328, 1749], ...}\n   2964             finally:\n   2965                 # Reset our crash handler in place\n   2966                 sys.excepthook = old_excepthook\n   2967         except SystemExit as e:\n\n...........................................................................\nC:\\Users\\Alexander\\PDSB\\project\\<ipython-input-189-7f2adb20e97e> in <module>()\n      1 with model:\n----> 2     trace = pm.sample(tune=1000, draws=5000, njobs=3, cores=3)\n\n...........................................................................\nC:\\Users\\Alexander\\Miniconda3\\lib\\site-packages\\pymc3\\sampling.py in sample(draws=6000, step=<pymc3.step_methods.hmc.nuts.NUTS object>, init='auto', n_init=200000, start=[{'means': array([ -4.62466574e-01,  -1.98349626e-01,   7.2...e+00,   4.53284820e-01,\n         2.34009797e-01]), 'packed_chol_cholesky_cov_packed__': array([-0.68384149, -0.02451297,  0.89029789, ..., -0.95576035,\n        0.00829716,  0.44670675])}, {'means': array([ -6.64825445e-01,  -4.51579275e-01,   2.2...e-01,   4.19604021e-01,\n         9.69156894e-01]), 'packed_chol_cholesky_cov_packed__': array([-0.84918792, -0.75632795, -0.9496933 , ...,  0.91648846,\n       -0.80776874,  0.31534939])}, {'means': array([ -9.26886577e-02,  -7.76855188e-02,  -6.0...e-02,   4.56617830e-01,\n        -7.67655805e-02]), 'packed_chol_cholesky_cov_packed__': array([-0.07061186,  0.33665793,  0.34348559, ..., -0.84164214,\n        0.84913171,  0.71964991])}], trace=None, chain_idx=0, chains=3, cores=3, tune=1000, nuts_kwargs=None, step_kwargs=None, progressbar=True, model=<pymc3.model.Model object>, random_seed=[701098618, 1069148487, 781561441], live_plot=False, discard_tuned_samples=True, live_plot_kwargs=None, compute_convergence_checks=True, use_mmap=False, **kwargs={'njobs': 3})\n    437     parallel = cores > 1 and chains > 1 and not has_population_samplers\n    438     if parallel:\n    439         _log.info('Multiprocess sampling ({} chains in {} jobs)'.format(chains, cores))\n    440         _print_step_hierarchy(step)\n    441         try:\n--> 442             trace = _mp_sample(**sample_args)\n        trace = None\n        sample_args = {'chain': 0, 'chains': 3, 'cores': 3, 'draws': 6000, 'live_plot': False, 'live_plot_kwargs': None, 'model': <pymc3.model.Model object>, 'njobs': 3, 'progressbar': True, 'random_seed': [701098618, 1069148487, 781561441], ...}\n    443         except pickle.PickleError:\n    444             _log.warning(\"Could not pickle model, sampling singlethreaded.\")\n    445             _log.debug('Pickling error:', exec_info=True)\n    446             parallel = False\n\n...........................................................................\nC:\\Users\\Alexander\\Miniconda3\\lib\\site-packages\\pymc3\\sampling.py in _mp_sample(**kwargs={'draws': 6000, 'live_plot': False, 'live_plot_kwargs': None, 'model': <pymc3.model.Model object>, 'njobs': 3, 'step': <pymc3.step_methods.hmc.nuts.NUTS object>, 'trace': None, 'tune': 1000})\n    977             for args in zip(chain_nums, pbars, rseed, start))\n    978 \n    979     if use_mmap:\n    980         traces = Parallel(n_jobs=cores)(jobs)\n    981     else:\n--> 982         traces = Parallel(n_jobs=cores, mmap_mode=None)(jobs)\n        traces = undefined\n        cores = 3\n        jobs = <generator object _mp_sample.<locals>.<genexpr>>\n    983 \n    984     return MultiTrace(traces)\n    985 \n    986 \n\n...........................................................................\nC:\\Users\\Alexander\\Miniconda3\\lib\\site-packages\\joblib\\parallel.py in __call__(self=Parallel(n_jobs=3), iterable=<generator object _mp_sample.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=3)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nMemoryError                                        Fri May 11 21:18:44 2018\nPID: 6440            Python 3.6.5: C:\\Users\\Alexander\\Miniconda3\\python.exe\n...........................................................................\nC:\\Users\\Alexander\\Miniconda3\\lib\\site-packages\\joblib\\parallel.py in __call__(self=<joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _sample>, (0, True, 701098618, {'means': array([ -4.62466574e-01,  -1.98349626e-01,   7.2...e+00,   4.53284820e-01,\n         2.34009797e-01]), 'packed_chol_cholesky_cov_packed__': array([-0.68384149, -0.02451297,  0.89029789, ..., -0.95576035,\n        0.00829716,  0.44670675])}), {'draws': 6000, 'live_plot': False, 'live_plot_kwargs': None, 'model': <pymc3.model.Model object>, 'njobs': 3, 'step': <pymc3.step_methods.hmc.nuts.NUTS object>, 'trace': None, 'tune': 1000})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Alexander\\Miniconda3\\lib\\site-packages\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _sample>\n        args = (0, True, 701098618, {'means': array([ -4.62466574e-01,  -1.98349626e-01,   7.2...e+00,   4.53284820e-01,\n         2.34009797e-01]), 'packed_chol_cholesky_cov_packed__': array([-0.68384149, -0.02451297,  0.89029789, ..., -0.95576035,\n        0.00829716,  0.44670675])})\n        kwargs = {'draws': 6000, 'live_plot': False, 'live_plot_kwargs': None, 'model': <pymc3.model.Model object>, 'njobs': 3, 'step': <pymc3.step_methods.hmc.nuts.NUTS object>, 'trace': None, 'tune': 1000}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Alexander\\Miniconda3\\lib\\site-packages\\pymc3\\sampling.py in _sample(chain=0, progressbar=True, random_seed=701098618, start={'means': array([ -4.62466574e-01,  -1.98349626e-01,   7.2...e+00,   4.53284820e-01,\n         2.34009797e-01]), 'packed_chol_cholesky_cov_packed__': array([-0.68384149, -0.02451297,  0.89029789, ..., -0.95576035,\n        0.00829716,  0.44670675])}, draws=6000, step=<pymc3.step_methods.hmc.nuts.NUTS object>, trace=None, tune=1000, model=<pymc3.model.Model object>, live_plot=False, live_plot_kwargs=None, **kwargs={'njobs': 3})\n    549                             tune, model, random_seed)\n    550     if progressbar:\n    551         sampling = tqdm(sampling, total=draws)\n    552     try:\n    553         strace = None\n--> 554         for it, strace in enumerate(sampling):\n        it = undefined\n        strace = None\n        sampling =   0%|          | 0/6000 [00:02<?, ?it/s]\n    555             if live_plot:\n    556                 if live_plot_kwargs is None:\n    557                     live_plot_kwargs = {}\n    558                 if it >= skip_first:\n\n...........................................................................\nC:\\Users\\Alexander\\Miniconda3\\lib\\site-packages\\tqdm\\_tqdm.py in __iter__(self=  0%|          | 0/6000 [00:02<?, ?it/s])\n    936             except AttributeError:\n    937                 raise TqdmDeprecationWarning(\"\"\"\\\n    938 Please use `tqdm_gui(...)` instead of `tqdm(..., gui=True)`\n    939 \"\"\", fp_write=getattr(self.fp, 'write', sys.stderr.write))\n    940 \n--> 941             for obj in iterable:\n        obj = undefined\n        iterable = <generator object _iter_sample>\n    942                 yield obj\n    943                 # Update and possibly print the progressbar.\n    944                 # Note: does not call self.update(1) for speed optimisation.\n    945                 n += 1\n\n...........................................................................\nC:\\Users\\Alexander\\Miniconda3\\lib\\site-packages\\pymc3\\sampling.py in _iter_sample(draws=6000, step=<pymc3.step_methods.hmc.nuts.NUTS object>, start={'means': array([ -4.62466574e-01,  -1.98349626e-01,   7.2...e+00,   4.53284820e-01,\n         2.34009797e-01]), 'packed_chol_cholesky_cov_packed__': array([-0.68384149, -0.02451297,  0.89029789, ..., -0.95576035,\n        0.00829716,  0.44670675])}, trace=None, chain=0, tune=1000, model=<pymc3.model.Model object>, random_seed=701098618)\n    637         pass\n    638 \n    639     point = Point(start, model=model)\n    640 \n    641     if step.generates_stats and strace.supports_sampler_stats:\n--> 642         strace.setup(draws, chain, step.stats_dtypes)\n        strace.setup = <bound method NDArray.setup of <pymc3.backends.ndarray.NDArray object>>\n        draws = 6000\n        chain = 0\n        step.stats_dtypes = [{'depth': <class 'numpy.int64'>, 'diverging': <class 'bool'>, 'energy': <class 'numpy.float64'>, 'energy_error': <class 'numpy.float64'>, 'max_energy_error': <class 'numpy.float64'>, 'mean_tree_accept': <class 'numpy.float64'>, 'step_size': <class 'numpy.float64'>, 'step_size_bar': <class 'numpy.float64'>, 'tree_size': <class 'numpy.float64'>, 'tune': <class 'bool'>}]\n    643     else:\n    644         strace.setup(draws, chain)\n    645 \n    646     try:\n\n...........................................................................\nC:\\Users\\Alexander\\Miniconda3\\lib\\site-packages\\pymc3\\backends\\ndarray.py in setup(self=<pymc3.backends.ndarray.NDArray object>, draws=6000, chain=0, sampler_vars=[{'depth': <class 'numpy.int64'>, 'diverging': <class 'bool'>, 'energy': <class 'numpy.float64'>, 'energy_error': <class 'numpy.float64'>, 'max_energy_error': <class 'numpy.float64'>, 'mean_tree_accept': <class 'numpy.float64'>, 'step_size': <class 'numpy.float64'>, 'step_size_bar': <class 'numpy.float64'>, 'tree_size': <class 'numpy.float64'>, 'tune': <class 'bool'>}])\n     60                                                        axis=0)\n     61         else:  # Otherwise, make array of zeros for each variable.\n     62             self.draws = draws\n     63             for varname, shape in self.var_shapes.items():\n     64                 self.samples[varname] = np.zeros((draws, ) + shape,\n---> 65                                                  dtype=self.var_dtypes[varname])\n        dtype = undefined\n        self.var_dtypes = {'cov': dtype('float64'), 'means': dtype('float64'), 'packed_chol': dtype('float64'), 'packed_chol_cholesky_cov_packed__': dtype('float64'), 'sigma': dtype('float64')}\n        varname = 'packed_chol'\n     66 \n     67         if sampler_vars is None:\n     68             return\n     69 \n\nMemoryError: \n___________________________________________________________________________"
     ]
    }
   ],
   "source": [
    "with model:\n",
    "    trace = pm.sample(tune=1000, draws=5000, njobs=3, cores=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "1 https://www.ncbi.nlm.nih.gov/pubmed/29198524\n",
    "\n",
    "2 https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE103322\n",
    "\n",
    "3 https://www.ncbi.nlm.nih.gov/pubmed/21219537\n",
    "\n",
    "4 https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4804254/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
